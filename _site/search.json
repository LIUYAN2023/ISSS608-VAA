[
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "title": "Hands-on_Ex08",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called tmap package.\n\n\n\nIn this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\nreadr for importing delimited text file, tidyr for tidying data, dplyr for wrangling data and sf for handling geospatial data. Among the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\n\nshow the code\npacman::p_load(sf, tmap, tidyverse)\n\n\n\nNotice that, we only need to install tidyverse instead of readr, tidyr and dplyr individually.\n\n\n\n\nTwo data set will be used to create the choropleth map. They are:\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\n\nshow the code\nmpsz <- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\LOLA\\Others\\Lola\\MITB Life\\Course\\ISSS608-Visual Analytics and Applications\\LIUYAN2023\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou can examine the content of mpsz by using the code chunk below.\n\n\nshow the code\nmpsz\n\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\n\nshow the code\npopdata <- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\n\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\nYOUNG: age group 0 to 4 until age groyup 20 to 24.\nECONOMY ACTIVE: age group 25-29 until age group 60-64.\nAGED: age group 65 and above.\nTOTAL: all age group.\nDEPENDENCY: the ratio between young and aged against economy active group.\n\n\n\nThe following data wrangling and transformation functions will be used:\npivot_wider() of tidyr package. mutate(), filter(), group_by() and select() of dplyr package.\n\n\nshow the code\npopdata2020 <- popdata %>%\n  filter(Time == 2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(`POP` = sum(`Pop`)) %>%\n  ungroup()%>%\n  pivot_wider(names_from=AG, \n              values_from=POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %>%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%>%\nmutate(`AGED`=rowSums(.[16:21])) %>%\nmutate(`TOTAL`=rowSums(.[3:21])) %>%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %>%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n\n\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other hand, the SUBZONE_N and PLN_AREA_N are in uppercase.\n\n\nshow the code\npopdata2020 <- popdata2020 %>%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %>%\n  filter(`ECONOMY ACTIVE` > 0)\n\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\n\nshow the code\nmpsz_pop2020 <- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nThing to learn from the code chunk above:\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\nshow the code\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\n\n\n\n\n\nTwo approaches can be used to prepare thematic map using tmap, they are:\nPlotting a thematic map quickly by using qtm(). Plotting highly customisable thematic map by using tmap elements.\n\n\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\n\nshow the code\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\nThings to learn from the code chunk above:\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\n\nshow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\n\nshow the code\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\n\nshow the code\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\nThings to learn from tm_polygons():\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\n\nshow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\n\nshow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\ncol = border colour, lwd = border line width. The default is 1, and lty = border line type. The default is “solid”.\n\n\n\n\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\n\nshow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\n\nshow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\n\nshow the code\nsummary(mpsz_pop2020$DEPENDENCY)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\n\nshow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\n\nshow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\n\nshow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\n\nshow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\n\nshow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\n\nshow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\n\nshow the code\ntmap_style(\"white\")\n\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\nby assigning multiple values to at least one of the asthetic arguments, by defining a group-by variable in tm_facets(), and by creating multiple stand-alone maps with tmap_arrange().\n\n\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\n\nshow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\n\nshow the code\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\n\nshow the code\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\n\nshow the code\nyoungmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\n\nshow the code\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\nProportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon, e.g. counts of people. Like choropleth maps, you can create classed or unclassed versions of these maps. The classed ones are known as range-graded or graduated symbols, and the unclassed are called proportional symbols, where the area of the symbols are proportional to the values of the attribute being mapped. In this hands-on exercise, you will learn how to create a proportional symbol map showing the number of wins by Singapore Pools’ outlets using an R package called tmap.\n\n\n\nBefore we get started, we need to ensure that tmap package of R and other related R packages have been installed and loaded into R.\n\n\nshow the code\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\n\n\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\n\nshow the code\nsgpools <- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\n\nshow the code\nlist(sgpools) \n\n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   <chr>          <chr>      <dbl>  <dbl>  <dbl> <chr>                     <dbl>\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame.\n\n\n\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages\n\n\nshow the code\nsgpools_sf <- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\n\nThings to learn from the arguments above:\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates. The crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\nYou can display the basic information of the newly created sgpools_sf by using the code chunk below.\n\n\nshow the code\nlist(sgpools_sf)\n\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * <chr>                        <chr>      <dbl> <chr>                     <dbl>\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry <POINT [m]>\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data.\n\n\n\n\nTo create an interactive proportional symbol map in R, the view mode of tmap will be used.\nThe code churn below will turn on the interactive mode of tmap.\n\n\nshow the code\ntmap_mode(\"view\")\n\n\n\n\nThe code chunks below are used to create an interactive point symbol map.\n\n\nshow the code\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\n\n\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\n\nshow the code\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\n\n\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\n\nshow the code\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1)\n\n\n\n\n\n\n\n\n\n\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\n\nshow the code\ntm_shape(sgpools_sf) +\n  tm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1) +\n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore you end the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\n\nshow the code\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#install-and-launching-r-packages-2",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#install-and-launching-r-packages-2",
    "title": "Hands-on_Ex08",
    "section": "3.1 Install and launching R Packages",
    "text": "3.1 Install and launching R Packages\n\n\nshow the code\npacman::p_load(tmap, tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-data",
    "title": "Hands-on_Ex08",
    "section": "3.2 Importing data",
    "text": "3.2 Importing data\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\n\n\nshow the code\nNGA_wp <- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#basic-choropleth-mapping",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#basic-choropleth-mapping",
    "title": "Hands-on_Ex08",
    "section": "3.3 Basic Choropleth Mapping",
    "text": "3.3 Basic Choropleth Mapping\n\n3.3.1 Visualising distribution of non-functional water point\n\n\nshow the code\np1 <- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water point by LGAs\",\n            legend.outside = FALSE)\n\n\n\n\nshow the code\np2 <- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total  water point by LGAs\",\n            legend.outside = FALSE)\n\n\n\n\nshow the code\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#choropleth-map-for-rates",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#choropleth-map-for-rates",
    "title": "Hands-on_Ex08",
    "section": "3.4 Choropleth Map for Rates",
    "text": "3.4 Choropleth Map for Rates\nIn much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n3.4.1 Deriving Proportion of Functional Water Points and Non-Functional Water Points\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\n\nshow the code\nNGA_wp <- NGA_wp %>%\n  mutate(pct_functional = wp_functional/total_wp) %>%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n\n3.4.2 Plotting map of rat\nPlot a choropleth map showing the distribution of percentage functional water point by LGA\n\n\nshow the code\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#extreme-value-maps",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#extreme-value-maps",
    "title": "Hands-on_Ex08",
    "section": "3.5 Extreme Value Maps",
    "text": "3.5 Extreme Value Maps\nExtreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n3.5.1 Percentile Map\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\nStep 1: Exclude records with NA by using the code chunk below.\n\n\nshow the code\nNGA_wp <- NGA_wp %>%\n  drop_na()\n\n\nStep 2: Creating customised classification and extracting values\n\n\nshow the code\npercent <- c(0,.01,.1,.5,.9,.99,1)\nvar <- NGA_wp[\"pct_functional\"] %>%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geomtry field.\n\n\n3.5.2 Why writing functions?\nWriting a function has three big advantages over using copy-and-paste:\nYou can give a function an evocative name that makes your code easier to understand. As requirements change, you only need to update code in one place, instead of many. You eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another). Source: Chapter 19: Functions of R for Data Science.\n\n3.5.2.1 Creating the get.var function\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\narguments: vname: variable name (as character, in quotes) df: name of sf data frame returns: v: vector with values (without a column name)\n\n\nshow the code\nget.var <- function(vname,df) {\n  v <- df[vname] %>% \n    st_set_geometry(NULL)\n  v <- unname(v[,1])\n  return(v)\n}\n\n\n\n\n3.5.2.2 A percentile mapping function\nNext, we will write a percentile mapping function by using the code chunk below.\n\n\nshow the code\npercentmap <- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent <- c(0,.01,.1,.5,.9,.99,1)\n  var <- get.var(vnam, df)\n  bperc <- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"< 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"> 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n\n3.5.2.3 Test drive the percentile mapping function\nTo run the function, type the code chunk as shown below.\n\n\nshow the code\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map.\n\n\n\n3.5.3 Box map\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\n\nshow the code\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n3.5.3.1 Creating the boxbreaks function\nThe code chunk below is an R function that creating break points for a box map.\narguments: v: vector with observations mult: multiplier for IQR (default 1.5) returns: bb: vector with 7 break points compute quartile and fences\n\n\nshow the code\nboxbreaks <- function(v,mult=1.5) {\n  qv <- unname(quantile(v))\n  iqr <- qv[4] - qv[2]\n  upfence <- qv[4] + mult * iqr\n  lofence <- qv[2] - mult * iqr\n  # initialize break points vector\n  bb <- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence < qv[1]) {  # no lower outliers\n    bb[1] <- lofence\n    bb[2] <- floor(qv[1])\n  } else {\n    bb[2] <- lofence\n    bb[1] <- qv[1]\n  }\n  if (upfence > qv[5]) { # no upper outliers\n    bb[7] <- upfence\n    bb[6] <- ceiling(qv[5])\n  } else {\n    bb[6] <- upfence\n    bb[7] <- qv[5]\n  }\n  bb[3:5] <- qv[2:4]\n  return(bb)\n}\n\n\n\n\n3.5.3.2 Creating the get.var function\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\narguments: vname: variable name (as character, in quotes) df: name of sf data frame returns: v: vector with values (without a column name)\n\n\nshow the code\nget.var <- function(vname,df) {\n  v <- df[vname] %>% st_set_geometry(NULL)\n  v <- unname(v[,1])\n  return(v)\n}\n\n\n\n\n3.5.3.3 Test drive the newly created function\nLet’s test the newly created function\n\n\nshow the code\nvar <- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n3.5.3.4 Boxmap function\nThe code chunk below is an R function to create a box map. - arguments: - vnam: variable name (as character, in quotes) - df: simple features polygon layer - legtitle: legend title - mtitle: map title - mult: multiplier for IQR - returns: - a tmap-element (plots a map)\n\n\nshow the code\nboxmap <- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var <- get.var(vnam,df)\n  bb <- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"< 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"> 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\n\n\nshow the code\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 1/In-class_Ex01.html",
    "href": "In-class Exercise/In-class Exercise 1/In-class_Ex01.html",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. if they are , then they will be lauched into R. - tidyverse: an opinionated collection of R packages designed for data science.\n\n\nshow the code\npacman::p_load(tidyverse)\n\n\n\n\n\n\n\nshow the code\nexam_data<-read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 1/In-class_Ex01.html#working-with-theme",
    "href": "In-class Exercise/In-class Exercise 1/In-class_Ex01.html#working-with-theme",
    "title": "In-class Exercise 1",
    "section": "2.1 Working with Theme",
    "text": "2.1 Working with Theme\n\n\nshow the code\nggplot(data=exam_data, aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal() +\n  theme(\n    panel.background = element_rect(fill = \"lightblue\", colour = \"lightblue\", \n                                    size = 0.5, linetype = \"solid\"),\n    panel.grid.major = element_line(size = 0.5, linetype = 'solid', colour = \"white\"), \n    panel.grid.minor = element_line(size = 0.25, linetype = 'solid', colour = \"white\"))"
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 1/In-class_Ex01.html#designing-data-drive-graphics-for-analysis-i",
    "href": "In-class Exercise/In-class Exercise 1/In-class_Ex01.html#designing-data-drive-graphics-for-analysis-i",
    "title": "In-class Exercise 1",
    "section": "2.2 Designing Data-drive Graphics for Analysis I",
    "text": "2.2 Designing Data-drive Graphics for Analysis I\n\n\nshow the code\nggplot(data=exam_data, \n       aes(x=reorder(RACE,RACE,\n                     function(x)-length(x)))) +\n  geom_bar() +\n  ylim(0,220) +\n  geom_text(stat=\"count\", \n      aes(label=paste0(..count.., \", \", \n      round(..count../sum(..count..)*100, 1), \"%\")),\n      vjust=-1) +\n  xlab(\"Race\") +\n  ylab(\"No. of\\nPupils\") +\n  theme(axis.title.y=element_text(angle = 0))"
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 1/In-class_Ex01.html#designing-data-drive-graphics-for-analysis-i-1",
    "href": "In-class Exercise/In-class Exercise 1/In-class_Ex01.html#designing-data-drive-graphics-for-analysis-i-1",
    "title": "In-class Exercise 1",
    "section": "2.3 Designing Data-drive Graphics for Analysis I",
    "text": "2.3 Designing Data-drive Graphics for Analysis I\n\n\nshow the code\nexam_data %>%\n  mutate(RACE = fct_infreq(RACE)) %>%\n  ggplot(aes(x = RACE)) + \n  geom_bar()+\n  ylim(0,220) +\n  geom_text(stat=\"count\", \n      aes(label=paste0(..count.., \", \", \n      round(..count../sum(..count..)*100,\n            1), \"%\")),\n      vjust=-1) +\n  xlab(\"Race\") +\n  ylab(\"No. of\\nPupils\") +\n  theme(axis.title.y=element_text(angle = 0))"
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 1/In-class_Ex01.html#designing-data-drive-graphics-for-analysis-iii",
    "href": "In-class Exercise/In-class Exercise 1/In-class_Ex01.html#designing-data-drive-graphics-for-analysis-iii",
    "title": "In-class Exercise 1",
    "section": "2.4 Designing Data-drive Graphics for Analysis III",
    "text": "2.4 Designing Data-drive Graphics for Analysis III\n\n\nshow the code\nd <- exam_data   \nd_bg <- d[, -3]  \n\nggplot(d, aes(x = ENGLISH, fill = GENDER)) +\n  geom_histogram(data = d_bg, fill = \"grey\", alpha = .5) +\n  geom_histogram(colour = \"black\") +\n  facet_wrap(~ GENDER) +\n  guides(fill = FALSE) +  \n  theme_bw()"
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 1/In-class_Ex01.html#designing-data-drive-graphics-for-analysis-iv",
    "href": "In-class Exercise/In-class Exercise 1/In-class_Ex01.html#designing-data-drive-graphics-for-analysis-iv",
    "title": "In-class Exercise 1",
    "section": "2.5 Designing Data-drive Graphics for Analysis IV",
    "text": "2.5 Designing Data-drive Graphics for Analysis IV\n\n\nshow the code\nggplot(data=exam_data, \n       aes(x=MATHS, y=ENGLISH)) +\n  geom_point() +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  geom_hline(yintercept=50,\n             linetype=\"dashed\",\n             color=\"grey60\",\n             size=1) + \n  geom_vline(xintercept=50, \n             linetype=\"dashed\",\n             color=\"grey60\",\n             size=1)"
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 4/In-class_Ex04.html",
    "href": "In-class Exercise/In-class Exercise 4/In-class_Ex04.html",
    "title": "In-class_Ex01",
    "section": "",
    "text": "show the code\nexam_data <- read_csv(\"data/Exam_data.csv\", show_col_types = FALSE)\n\n\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\nshow the code\nggplot(exam_data,\n       aes(sample=ENGLISH))+stat_qq()+stat_qq_line()\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nwe can see that the points deviate significantly form the straight diagonal line. this is a clear indication that the set of data is not normally distributed.\n\n\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\nshow the code\nqq <- ggplot(exam_data,\n       aes(sample=ENGLISH))+stat_qq()+stat_qq_line()\n\nsw_t <- exam_data %>%\n  shapiro_test(ENGLISH)%>%\n  gt()\n\ntmp <- tempfile(fileext = '.png')\ngtsave(sw_t,tmp)\ntable_png <- png::readPNG(tmp,\n                        native=TRUE)\n\nqq+table_png"
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 5/In-class_Ex05.html",
    "href": "In-class Exercise/In-class Exercise 5/In-class_Ex05.html",
    "title": "In-class_Ex05",
    "section": "",
    "text": "show the code\nMC1 <- fromJSON(\"data/MC1.json\")\n\n\n\n\nshow the code\nMC1_nodes<- as_tibble(MC1$nodes) %>%\n  select(id,type,country)\n\nMC1_edges<- as_tibble(MC1$links) %>%\n  select(source,target, type, weight,key)"
  },
  {
    "objectID": "Take-home Exercise/Take-home Exercise 1/Take-home_Ex01.html",
    "href": "Take-home Exercise/Take-home Exercise 1/Take-home_Ex01.html",
    "title": "Take-home_Ex01",
    "section": "",
    "text": "City of Engagement, with a total population of 50,000, is a small city located at Country of Nowhere. The city serves as a service centre of an agriculture region surrounding the city. The main agriculture of the region is fruit farms and vineyards. The local council of the city is in the process of preparing the Local Plan 2023. A sample survey of 1000 representative residents had been conducted to collect data related to their household demographic and spending patterns, among other things. The city aims to use the data to assist with their major community revitalization efforts, including how to allocate a very large city renewal grant they have recently received.\n\nThis exercise aims to reveal the demographic and financial characteristics of the city of Engagement by using appropriate static and interactive statistical graphics methods. User-friendly and interactive solution will help planners to explore the complex data in an engaging way and reveal hidden patterns."
  },
  {
    "objectID": "Take-home Exercise/Take-home Exercise 1/Take-home_Ex01.html#install-r-packages-and-import-dataset",
    "href": "Take-home Exercise/Take-home Exercise 1/Take-home_Ex01.html#install-r-packages-and-import-dataset",
    "title": "Take-home_Ex01",
    "section": "2.1 Install R Packages and Import Dataset",
    "text": "2.1 Install R Packages and Import Dataset\nThe code chunk below uses pacman::p_load() to check if packages are installed. If they are, they will be launched into R. The packages installed are\npacthwork: Used to combine plots.\nDT:provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse: A collection of core packages designed for data science, used extensively for data preparation and wrangling.\nrstatix: coherent with the ‘tidyverse’ design philosophy, for performing basic statistical tests, including t-test, Wilcoxon test, ANOVA, Kruskal-Wallis and correlation analyses.\nplotly: Used for creating interactive web-based graphs.\nggstatsplot: Used for creating graphics with details from statistical tests.\nggdist: Used for visualising distribution and uncertainty.\npng: read, write and display bitmap images stored in the PNG format.\nggthemes: Provide additional themes for ggplot2.\nggplot2:ggplot2 is a system for declaratively creating graphics.\nggiraph:ggiraph is a tool that allows you to create dynamic ggplot graphs.\ntreemap:offers great flexibility to draw treemaps.\ngridExtra:Provides a number of user-level functions to work with “grid” graphics, notably to arrange multiple grid-based plots on a page, and draw tables.\nggpubr:provides some easy-to-use functions for creating and customizing ‘ggplot2’- based publication ready plots.\ngt:Easily Create Presentation-Ready Display Tables.\nggridges:a ggplot2 extension specially designed for plotting ridgeline plots.\nAll packages can be found within CRAN.\n\n\nshow the code\npacman::p_load(patchwork, DT,tidyverse, rstatix, plotly, ggstatsplot, ggdist, png,ggthemes, ggplot2, ggiraph, treemap,gridExtra, ggpubr,gt,ggridges)\n\n\nDownload the data set\n\n\nshow the code\nFinancialJournal <- read_csv(\"data/FinancialJournal.csv\")\nParticipants <- read_csv(\"data/Participants.csv\")"
  },
  {
    "objectID": "Take-home Exercise/Take-home Exercise 1/Take-home_Ex01.html#data-introduction",
    "href": "Take-home Exercise/Take-home Exercise 1/Take-home_Ex01.html#data-introduction",
    "title": "Take-home_Ex01",
    "section": "2.2 Data Introduction",
    "text": "2.2 Data Introduction\nFor the purpose of this study, two data sets are provided. They are:\nParticipants.csv\nContains information about the residents of City of Engagement that have agreed to participate in this study.\nparticipantId (integer): unique ID assigned to each participant.\nhouseholdSize (integer): the number of people in the participant’s household\nhaveKids (boolean): whether there are children living in the participant’s household.\nage (integer): participant’s age in years at the start of the study.\neducationLevel (string factor): the participant’s education level, one of: {“Low”, “HighSchoolOrCollege”, “Bachelors”, “Graduate”}\ninterestGroup (char): a char representing the participant’s stated primary interest group, one of {“A”, “B”, “C”, “D”, “E”, “F”, “G”, “H”, “I”, “J”}. Note: specific topics of interest have been redacted to avoid bias.\njoviality (float): a value ranging from [0,1] indicating the participant’s overall happiness level at the start of the study.\nFinancialJournal.csv\nContains information about financial transactions.\nparticipantId (integer): unique ID corresponding to the participant affected\ntimestamp (datetime): the time when the check-in was logged\ncategory (string factor): a string describing the expense category, one of {“Education”, “Food”, “Recreation”, “RentAdjustment”, “Shelter”, “Wage”}\namount (double): the amount of the transaction"
  },
  {
    "objectID": "Take-home Exercise/Take-home Exercise 1/Take-home_Ex01.html#data-cleaning-and-wrangling",
    "href": "Take-home Exercise/Take-home Exercise 1/Take-home_Ex01.html#data-cleaning-and-wrangling",
    "title": "Take-home_Ex01",
    "section": "2.3 Data Cleaning and Wrangling",
    "text": "2.3 Data Cleaning and Wrangling\n\n2.3.1 Data Issue and Modification\n\n\n\n\n\n\n\n\nItem\nIssue\nSolution\n\n\n\n\n1\nwrong data type\ncheck & modify all the variable’s data type as per the data type indicated in dataset description\n\n\n2\n“RentAdjustment” is the refundable portion of rent, which belongs to the “shelter”\nreplace all the “RentAdjustment” with “shelter”\n\n\n3\n“timestamp” format is too complicated and not useable.\nConsider all the record belong to same year, so change “timestamp” to “month”\n\n\n4\nthere are 1,113 rows data are duplicates\nremove all duplicate rows in the FinancialJournal data table\n\n\n5\n131 nos of participantId only have less than 12 months record\nremove the rows with less than 12 months record\n\n\n\n\n\nshow the code\n# 1.Modify the data type###########################################################\n\n# Convert participantId from numeric to integer\nFinancialJournal$participantId <- as.integer(FinancialJournal$participantId)\n\n# Convert category from character to string factor with specified levels\nFinancialJournal$category <- factor(FinancialJournal$category, levels = c(\"Education\", \"Food\", \"Recreation\", \"RentAdjustment\", \"Shelter\", \"Wage\"))\n\n# Convert amount from numeric to double\nFinancialJournal$amount <- as.double(FinancialJournal$amount)\n\n# Convert participantId from numeric to integer\nParticipants$participantId <- as.integer(Participants$participantId)\n\n# Convert householdSize from numeric to integer\nParticipants$householdSize <- as.integer(Participants$householdSize)\n\n# Convert haveKids from logical to Boolean\nParticipants$haveKids <- as.logical(Participants$haveKids)\n\n# Convert age from numeric to integer\nParticipants$age <- as.integer(Participants$age)\n\n# Convert educationLevel from character to string factor with specified levels\nParticipants$educationLevel <- factor(Participants$educationLevel, levels = c(\"Low\", \"HighSchoolOrCollege\", \"Bachelors\", \"Graduate\"))\n\n# Convert joviality from numeric to float\nParticipants$joviality <- as.double(Participants$joviality)\n\n\n# 2. Replace all the \"RentAdjustment\" with \"shelter\"###############################\n\nFinancialJournal$category <- factor(ifelse(FinancialJournal$category == \"RentAdjustment\", \"Shelter\", as.character(FinancialJournal$category)))\n\n# 3. Extract new variable month from the timestamp#################################\n\nFinancialJournal <- FinancialJournal %>% \n  mutate(month = month(timestamp))\n\n# 4. Remove all duplicate rows in the FinancialJournal#############################\n\n# Check duplicate rows in the FinancialJournal data table\n# sum(duplicated(FinancialJournal))\n\n# Remove all duplicate rows in the FinancialJournal\nFinancialJournal <- distinct(FinancialJournal)\n\n\n# 5. remove the rows with less than 12 months record###############################\n\n# check the row with less than 12 months record\n#FinancialJournal %>% \n#  group_by(participantId) %>% \n#  filter(n_distinct(month) < 12) %>% \n#  distinct(participantId)\n\n# remove the rows with less than 12 months record\nFinancialJournal %>%\n  group_by(participantId) %>%\n  mutate(month_count = n_distinct(month)) %>%\n  filter(month_count >= 12) %>%\n  select(-month_count) -> FinancialJournal\n\n\n\n\n2.3.2 Reshape FinancialJournal and Data Table Join\nTo conduct a comprehensive analysis of participant demographics and their financial status, we implemented following steps:\n\nPerform a grouping operation on the “FinancialJournal” using the “participantId” and “category” variables, to obtain each participant’s monthly expenditure across different categories.\nReshape the new table to “Financial_wide”. Each row of “Financial_wide” contains one participant’s financial expenditures and income information.\nMerge the “Financial_wide” and “Participants” tables by the “participantId” variable, creating a new table “joined_table” that contains comprehensive information on participant demographic, expenditures, and income.\n\n\n\nshow the code\n# Group the rows of the \"FinancialJournal\" data table by \"participantId\" and \"category\"\nFinancial_sum <- FinancialJournal %>%\n  group_by(participantId, category) %>%\n  summarise(average_amount = sum(amount)/12) \n\n\n# Reshape the Financial_sum and make each \"category\" becomes a separate column \nFinancial_wide <- Financial_sum %>%\n  spread(category, average_amount)\n\n\n# Join the two Participants and Financial_wide by participantId\n\njoined_table <- Participants %>% \n                inner_join(Financial_wide, by = \"participantId\")\n\n\n\n\n2.3.3 New Variable Wrangling\nTo better utilize the available variables, we create several new variables as part of our data analysis process.\nTotal_Expenditure: aggregating all monthly expenditures on education, food, recreation, and shelter. This variable provides insight into the overall cost of living for each participant.\nSaving_Ratio: the difference between wage and total_expenditure divided by wage. This variable is a useful indicator of financial health and reflects the proportion of income that is being saved or invested for future needs.\nage_bin: binning the “age” variable into discrete categories based on the following age ranges: “<=30”, “>30 - 40”, “>40 - 50”, and “>50”. This variable serves as a categorical variable and enables us to analyze the characteristics of different age groups.\nWage_bin: binning the “wage” variable into income categories based on the following ranges: “<3000”, “3000 - <4000”, “4000 - <5000”, and “>=5000”. This variable serves as a categorical variable and facilitates the analysis of different income groups.\n\n\nshow the code\n# Create new columns \"Total_Expenditure\" and \"Saving_Ratio\"\njoined_table <- joined_table %>%\n  mutate(across(c(Education, Food, Recreation, Shelter), ~replace_na(., 0)),\n        Total_Expenditure = (Education + Food + Recreation + Shelter),\n        Saving_Ratio =( (Wage + Total_Expenditure)/Wage))\n        \n# Create age_bin column\njoined_table$age_bin <- cut(joined_table$age, \n                            breaks = c(-Inf, 30, 40, 50, Inf),\n                            labels = c(\"<=30\", \">30-40\", \">40-50\", \">50\"))\n\n# Create Wage_bin column\njoined_table$Wage_bin <- cut(joined_table$Wage,\n                             breaks = c(-Inf, 3000, 4000, 5000, Inf),\n                             labels = c(\"<3000\", \"3000-<4000\", \"4000-<5000\", \">=5000\"))\n\n\nShow the datatable after data cleaning & wrangling\n\n\nshow the code\n# Generate the datatable\nDT::datatable(joined_table, class= \"compact\")"
  },
  {
    "objectID": "Take-home Exercise/Take-home Exercise 1/Take-home_Ex01.html#analysis-on-participant-profile",
    "href": "Take-home Exercise/Take-home Exercise 1/Take-home_Ex01.html#analysis-on-participant-profile",
    "title": "Take-home_Ex01",
    "section": "3.1 Analysis on Participant Profile",
    "text": "3.1 Analysis on Participant Profile\nInitially, our analysis will entail a comprehensive review of the participant profile in order to obtain a holistic understanding of the sample population’s characteristics, which will serve as a foundation for subsequent result analysis.\n\n3.1.1 Age Distribution\nThe age range of the participants is between 15 and 60 years old, and the distribution appears to be relatively even with a notable proportion of individuals in middle age.\n\n\nshow the code\n#Creating a plot object using ggplot \np <- ggplot(data=Participants, aes(x = age)) +\n  #Adding an interactive dotplot layer\n  geom_dotplot_interactive(         \n    aes(data_id = interestGroup),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\",\n    dotsize = 0.5) +\n  scale_y_continuous(NULL, breaks = NULL)\n\n#Creating an interactive plot using girafe\ngirafe(\n  ggobj = p,                             \n  width_svg = 10,                         \n  height_svg = 10*0.618,\n  #Adding hover options\n  options = list(\n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )\n)\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nElements associated with interestGroup will be highlighted upon mouse over.\n\n\n\n\n3.1.2 Age vs HaveKids Pyramid\nFrom Age vs HaveKids pyramid, we can find there is a higher prevalence of individuals without children across various age levels in the participant population.\n\n\nshow the code\n# create age groups using cut function\nParticipants$age_level <- cut(Participants$age, breaks = seq(0, 100, by = 5), include.lowest = TRUE)\n\n# aggregate data by age level and haveKids\nAge_haveKids <- aggregate(participantId ~ age_level + haveKids, data = Participants, FUN = length)\n\n# rename the column to population\ncolnames(Age_haveKids)[3] <- \"population\"\n\n# sort the data by age level and haveKids\nAge_haveKids <- Age_haveKids[order(Age_haveKids$age_level, Age_haveKids$haveKids), ]\n\nAge_haveKids$population <- ifelse(Age_haveKids$haveKids == \"TRUE\",-1*Age_haveKids$population,Age_haveKids$population)\n\nage_cohort <- ggplot(Age_haveKids,aes(x = age_level, y = population,fill = haveKids))+\n  geom_bar(stat = \"identity\") +\n  scale_y_continuous(breaks = seq(-150, 150, 50), \n                     labels = paste0(as.character(c(seq(150, 0, -50), seq(50, 150, 50))))) +\n  coord_flip()\n\nage_cohort +\n  ggtitle(\"Participant Population by HaveKids\")+\n  xlab(\"Age Group\")+\n  ylab(\"Population\")+\n  scale_fill_manual(values=c('lightpink2','steelblue3'))+\n  theme_economist()+\n  theme(legend.position='right')\n\n\n\n\n\n\n\n3.1.3 Tree Map for InterestGroup\nIt is evident that the population of the different interest groups is comparable, with J and H showing marginally higher proportions.\n\n\nshow the code\n# calculate total number of participants\ntotal <- nrow(Participants)\n\n# aggregate data by interest group\nInterest_population <- aggregate(participantId ~ interestGroup, data = Participants, FUN = length)\n\n# calculate proportion of each interest group\nInterest_population$proportion <- round(Interest_population$participantId / total * 100, 2)\n\n# create treemap\ntreemap(Interest_population, index = c(\"interestGroup\"), vSize = \"proportion\",\n        type = \"index\", palette = \"Blues\", title = \"Proportion of Participants by Interest Group\")"
  },
  {
    "objectID": "Take-home Exercise/Take-home Exercise 1/Take-home_Ex01.html#analysis-on-financial-situation",
    "href": "Take-home Exercise/Take-home Exercise 1/Take-home_Ex01.html#analysis-on-financial-situation",
    "title": "Take-home_Ex01",
    "section": "3.2 Analysis on Financial Situation",
    "text": "3.2 Analysis on Financial Situation\nIn this section, we will focus on participant’s financial situation to analyse which factor has association with people’s income, and the difference in saving ration and total_expenditure under different group.\n\n3.2.1 Wage Distribution by Month\nThe salary distribution exhibits a mild right skew, and the aggregate salary level for March surpasses that of other months.\n\n\nshow the code\n# Groupe the rows of the \"FinancialJournal\" data table by \"participantId\" ,\"month\"and \"category\"\nFinancial_sum1 <- FinancialJournal %>%\n  group_by(participantId, category,month) %>%\n  summarise(average_amount1 = sum(amount)/12) \n\n# Reshape the Financial_sum and make each \"category\" becomes a separate column \nFinancial_wide1 <- Financial_sum1 %>%\n  spread(category, average_amount1)\n\n# Conver the month to factor data type\nFinancial_wide1$month <- factor(Financial_wide1$month, levels = c(\"1\", \"2\", \"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\"))\n\n#Create a density ridgeline plot to visualize the distribution of wages over months\nggplot(Financial_wide1,\n       aes(x = Wage, \n           y = month, \n           fill = factor(stat(quantile))\n           )) +\n  #Create density ridgelines\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\n\n\n\n3.2.2 Association Between Wage and Education/Age/Interset\nSignificant test of association (dependence) is an essential statistical technique used to determine whether two variables are related or associated with each other. One of the useful tools for performing this test in R is the ggbarstats().\n\nWage_bin vs EducationLevelWage_bin vs Age_binWage_bin vs HaveKids\n\n\n\n\nshow the code\n# Wage_bin vs EducationLevel\nggbarstats(joined_table, \n           x = Wage_bin, \n           y = educationLevel)\n\n\n\n\n\n\n\n\n\nshow the code\n# Wage_bin vs Age_bin\nggbarstats(joined_table, \n           x = age_bin, \n           y = haveKids)\n\n\n\n\n\n\n\n\n\nshow the code\n# Wage_bin vs HaveKids\nggbarstats(joined_table, \n           x = Wage_bin, \n           y = haveKids)\n\n\n\n\n\n\n\n\nSignificant Test of Association between Wage_bin vs educationLevel:\nThe result of this test suggests that there is a significant association between the variables “Wage_bin” and “educationLevel” in the dataset, as indicated by the low p-value (p=2.82e-69) and the high value of the X2pearson statistic (X2pearson(9)=346.91).\nThe V ̂cramerstatistic also indicates a moderate degree of association (V ̂ cramer =0.36). The CI95%[0.32,1.00] suggests that there is a 95% chance that the true value of the association between these variables falls within this interval, with a lower bound of 0.32 and an upper bound of 1.00.\nFinally, the Nobs value of 880 indicates that there were 880 observations used in the analysis.\nInsight:\n1. There is a significant association between “Wage_bin” and “educationLevel” in the dataset.\n- Nearly half of the survey participants belong to the high school or college student, or low education group, who report a relatively lower average monthly income.\n- Graduates have the highest representation in the high income group, followed by those with a bachelor’s degree.\n2. There is no association between the variables “Wage_bin” and ” Age_bin”, with P value = 0.44.\n3. There is a significant association between the variables “Wage_bin” and ” haveKids” in the dataset, people tend to have kids when they have a relatively higher income.\n\n\n3.2.3 Boxplot of Saving Ratio/Total_Expenditure\nA boxplot, also known as a box and whisker plot, is a graphical representation used to display the spread and central tendency of a dataset. It provides measures of spread such as the interquartile range and mean, as well as measures of center such as the median and mean.\n\nBoxplot of Saving Ratio\n\n\nshow the code\n#Create a box plot using plot_ly with specified layout and drop-down menu options\nplot_ly(data = joined_table,\n        x = ~educationLevel,\n        y = ~Saving_Ratio,\n        line = list(width =1),\n        type = \"box\",\n        colors = \"YlGnBu\",\n        showlegend = FALSE,\n        boxmean = TRUE\n        ) %>%\n \n  # Adding layout options, including a drop-down menu for selecting factors\n  layout(title = \"Boxplot of Saving Ratio by Selected Factors \",\n         xaxis = list(title = \"\"),\n         yaxis = list(title = \"Saving Ratio\"),\n         \n         updatemenus = list(list(type = 'dropdown',\n                         xref = \"paper\",\n                         yref = \"paper\",\n                         xanchor = \"left\",\n                         x = 0.01, \n                         y = 0.99,\n                         buttons = list(\n                           list(method = \"update\",\n                                args = list(list(x = list(joined_table$educationLevel)),\n                                            list(xaxis = list(categoryorder = \"category ascending\"))),\n                                label = \"educationLevel\"),\n                           list(method = \"update\",\n                                args = list(list(x = list(joined_table$haveKids)),\n                                            list(xaxis = list(categoryorder = \"category ascending\"))),\n                                label = \"haveKids\"),\n                          list(method = \"update\",\n                                args = list(list(x = list(joined_table$householdSize)),\n                                            list(xaxis = list(categoryorder = \"category ascending\"))),\n                                label = \"householdSize\")\n                           \n                         )\n                    )\n         )\n\n)\n\n\n\n\n\n\n\nSaving Ratio vs Education Level: it can be observed that graduates have the highest mean saving ratio, while those with low education level have the lowest mean saving ratio. Moreover, it is worth noting that there is a higher presence of outliers for the group of graduates.\nSaving Ratio vs Have Kids: the box plot indicates that both groups, i.e., those with and without kids, have similar mean and median saving ratios. However, the dispersion, as measured by the interquartile range, is smaller for the group of individuals who have kids.\nSaving Ratio vs Household Size: the box plot reveals that the median saving ratio for households with two people is lower compared to those household size with one or three people. Additionally, the group with one person in the household has the largest dispersion of saving ratios.\n\n\n\nBoxplot of Total_Expenditure\n\n\nshow the code\n# Create new column  \"Total_livingcost\" by taking the absolute value of \"Total_Expenditure\".\njoined_table$Total_livingcost <- abs(joined_table$Total_Expenditure)\n\n#Create a box plot using plot_ly with specified layout and drop-down menu options\nplot_ly(data = joined_table,\n        x = ~educationLevel,\n        y = ~Total_livingcost,\n        line = list(width =1),\n        type = \"box\",\n        colors = \"YlGnBu\",\n        showlegend = FALSE,\n        boxmean = TRUE\n        ) %>%\n \n  # Adding layout options, including a drop-down menu for selecting factors\n  layout(title = \"Boxplot of Total_Expenditure by selected factors \",\n         xaxis = list(title = \"\"),\n         yaxis = list(title = \"Total_Expenditure\"),\n         \n         updatemenus = list(list(type = 'dropdown',\n                         xref = \"paper\",\n                         yref = \"paper\",\n                         xanchor = \"left\",\n                         x = 0.01, \n                         y = 0.99,\n                         buttons = list(\n                           list(method = \"update\",\n                                args = list(list(x = list(joined_table$educationLevel)),\n                                            list(xaxis = list(categoryorder = \"category ascending\"))),\n                                label = \"educationLevel\"),\n                           list(method = \"update\",\n                                args = list(list(x = list(joined_table$haveKids)),\n                                            list(xaxis = list(categoryorder = \"category ascending\"))),\n                                label = \"haveKids\"),\n                          list(method = \"update\",\n                                args = list(list(x = list(joined_table$householdSize)),\n                                            list(xaxis = list(categoryorder = \"category ascending\"))),\n                                label = \"householdSize\")\n                              \n                           \n                         )\n                    )\n         )\n\n)\n\n\n\n\n\n\n\nTotal Expenditure vs Education Level: the mean monthly living cost does not vary significantly among different education levels. Besides, the dispersion of the monthly living cost is smaller for individuals with a lower level of education and for those with a high school or college degree, compared to those with a bachelor’s or graduate degree.\nTotal Expenditure vs Have Kids : In comparing the mean monthly living costs of demographic groups with and without children, it was found that households with children experience a higher mean average monthly cost of living compared to those without.\nTotal Expenditure vs household size : it can be observed that as the household size increases, the total living cost also increases."
  },
  {
    "objectID": "Take-home Exercise/Take-home Exercise 1/Take-home_Ex01.html#analysis-on-joviality",
    "href": "Take-home Exercise/Take-home Exercise 1/Take-home_Ex01.html#analysis-on-joviality",
    "title": "Take-home_Ex01",
    "section": "3.3 Analysis on Joviality",
    "text": "3.3 Analysis on Joviality\nMaintaining a jovial attitude can be a contributing factor to a more harmonious social environment and can improve overall well-being. In this section, we will conduct an analysis of the factors that affect citizens’ joviality and explore the differences in joviality levels across various demographic groups.\n\n3.3.1 Significant Test of Correlation\n\n\nshow the code\n# Define two scatter plots with ggscatterstats function\np1 <- ggscatterstats(\ndata = joined_table,\nx = Saving_Ratio,\ny = joviality,\nmarginal = FALSE,\n) +\n#Set the horizontal position of the title to the center of the plot\ntheme(plot.title = element_text(hjust = 0.5)) +\nggtitle(\"Joviality and Saving_Ratio\")\n\np2 <- ggscatterstats(\ndata = joined_table,\nx = Wage,\ny = joviality,\nmarginal = FALSE,\n) +\n#Set the horizontal position of the title to the center of the plot\ntheme(plot.title = element_text(hjust = 0.5)) +\nggtitle(\"Joviality and Wage\")\n\np1 + p2\n\n\n\n\n\n\n\nshow the code\n# Define two scatter plots with ggscatterstats function\njoined_table$Recreation_cost <- abs(joined_table$Recreation)\np3 <- ggscatterstats(\ndata = joined_table,\nx = Recreation_cost,\ny = joviality,\nmarginal = FALSE,\n) +\n#Set the horizontal position of the title to the center of the plot\ntheme(plot.title = element_text(hjust = 0.5)) +\nggtitle(\"Joviality and Recreation_cost\")\n\njoined_table$Food_cost <- abs(joined_table$Food)\np4 <- ggscatterstats(\ndata = joined_table,\nx = Food_cost,\ny = joviality,\nmarginal = FALSE,\n) +\n#Set the horizontal position of the title to the center of the plot\ntheme(plot.title = element_text(hjust = 0.5)) +\nggtitle(\"Joviality and Food_cost\")\n\np3+p4\n\n\n\n\n\nThese results suggest that there are significant correlations between joviality and the variables of Saving_Ratio, Recreation, and Food, but a weaker correlation with Wage.\n\nThe p-values for all four tests are very small, indicating a low likelihood of obtaining such strong correlations by chance.\nThe signs of the correlation coefficients suggest that as Recreation, and Food increase, Joviality tends to increase as well, whereas for saving ratio and Wage, Joviality tends to decrease as these two variables increases.\nThe correlation coefficient rPreason measures the strength and direction of the linear relationship between the variables. In this case, a value of -0.56, -0.3, 0.55, and 0.57 respectively suggests a moderate to strong negative correlation for Saving_Ratio and Wage, and moderate to strong positive correlation for Recreation and Food.\n\n\n\n3.3.2 Oneway ANOVA Test of Joviality\n\n\nNormality Assumption\nBefore performing the necessary hypothesis testing, we need to choose between parametric and non-parametric test. perform Shapiro-Wilk normality test with confidence level of 95% to test the null hypothesis that the joviality by different factor(education_level,age,have kids) is normally distributed.\n\nJoviality by EducationLevelJoviality by Age_binJoviality by HaveKids\n\n\n\n\nshow the code\n# Create a data frame with two variables\ndf <- data.frame(\n  group = joined_table$educationLevel,\n  joviality = joined_table$joviality\n)\n\n# Create a QQ plot with a normal distribution line \nqq_plot <- ggplot(df, aes(sample = joviality)) +\n  stat_qq() + \n  stat_qq_line() +\n  facet_wrap(~group)\n\n# Perform Shapiro-Wilk normality test \ntable_gts <- lapply(unique(df$group), function(x) {\n  sw_t <- df %>%\n    filter(group == x) %>%\n    shapiro_test(joviality) %>%\n    gt()\n  tmp <- tempfile(fileext = '.png')\n  gtsave(sw_t, tmp)\n  png::readPNG(tmp, native = TRUE)\n})\n\n# Arrange the QQ plots of each education level group in a grid\nggarrange(qq_plot, ncol = 1, nrow = 1)\n\n\n\n\n\n\n\n\n\nshow the code\n# Create a data frame with two variables\ndf <- data.frame(\n  group = joined_table$age_bin,\n  joviality = joined_table$joviality\n)\n\n# Create a QQ plot with a normal distribution line \nqq_plot <- ggplot(df, aes(sample = joviality)) +\n  stat_qq() + \n  stat_qq_line() +\n  facet_wrap(~group)\n\n# Perform Shapiro-Wilk normality test \ntable_gts <- lapply(unique(df$group), function(x) {\n  sw_t <- df %>%\n    filter(group == x) %>%\n    shapiro_test(joviality) %>%\n    gt()\n  tmp <- tempfile(fileext = '.png')\n  gtsave(sw_t, tmp)\n  png::readPNG(tmp, native = TRUE)\n})\n\n\n# Arrange the QQ plots of each education level group in a grid\nggarrange(qq_plot, ncol = 1, nrow = 1)\n\n\n\n\n\n\n\n\n\nshow the code\n# Create a data frame with two variables\ndf <- data.frame(\n  group = joined_table$haveKids,\n  joviality = joined_table$joviality\n)\n\n# Create a QQ plot with a normal distribution line\nqq_plot <- ggplot(df, aes(sample = joviality)) +\n  stat_qq() + \n  stat_qq_line() +\n  facet_wrap(~group)\n\n# Perform Shapiro-Wilk normality test \ntable_gts <- lapply(unique(df$group), function(x) {\n  sw_t <- df %>%\n    filter(group == x) %>%\n    shapiro_test(joviality) %>%\n    gt()\n  tmp <- tempfile(fileext = '.png')\n  gtsave(sw_t, tmp)\n  png::readPNG(tmp, native = TRUE)\n})\n\n# Arrange the QQ plots of each education level group in a grid\nggarrange(qq_plot, ncol = 1, nrow = 1)\n\n\n\n\n\n\n\n\nBased on the result above, the null hypothesis is rejected as some of the distributions are below 0.05 critical value. As such, we are not able to confirm normality assumption for distribution of joviality by education_level/age/have kids.\n\n\n\n\n\n\nNote\n\n\n\nSince we are unable to confirm normality assumption, non-parametric test (Kruskal-Wallis and Mann-Whitney) will be used for hypothesis testing. Note that the null hypothesis is no difference between median joviality by EducationLevel/Age_bin/HaveKids.\n\n\n\nJoviality by EducationLevelJoviality by Age_binJoviality by HaveKids\n\n\n\n\nshow the code\n#set the color pallete\ncol13_1 <- c(\"dodgerblue2\", \"#E31A1C\", \n  \"green4\",\n  \"#6A3D9A\", \n  \"#FF7F00\", \n  \"gray30\", \"gold1\",\n  \"skyblue2\", \"#FB9A99\", \n  \"palegreen2\",\n  \"#CAB2D6\", \n  \"#FDBF6F\", \n  \"gray80\") \n  \n#Initiating the base plot\np1 <- ggbetweenstats(\n  data = joined_table|> \n    group_by(educationLevel),\n  x = educationLevel, \n  y = joviality, \n  ylab = \"joviality\",\n  title = \"One-way ANOVA Reveal Difference on Joviality across Different Education Level\",\n  type = \"np\", \n  pairwise.comparisons = TRUE,\n  pairwise.display = \"ns\",\n  mean.ci = TRUE,\n  p.adjust.method = \"fdr\", \n  messages = FALSE \n  ) +\n  scale_color_manual(values = col13_1) +\n  theme(axis.title.x = element_blank()) +\n  scale_y_continuous(limits = c(0, 1))\n\np1\n\n\n\n\n\n\n\n\n\nshow the code\n#set the color pallete\ncol13_1 <- c(\"dodgerblue2\", \"#E31A1C\", \n  \"green4\",\n  \"#6A3D9A\", \n  \"#FF7F00\", \n  \"gray30\", \"gold1\",\n  \"skyblue2\", \"#FB9A99\", \n  \"palegreen2\",\n  \"#CAB2D6\", \n  \"#FDBF6F\", \n  \"gray80\") \n  \n#Initiating the base plot\np2 <- ggbetweenstats(\n  data = joined_table|> \n    group_by(age_bin),\n  x = age_bin, \n  y = joviality, \n  ylab = \"joviality\",\n  title = \"One-way ANOVA Reveal Difference on Joviality across Different Age Range\",\n  type = \"np\", \n  pairwise.comparisons = TRUE,\n  pairwise.display = \"ns\",\n  mean.ci = TRUE,\n  p.adjust.method = \"fdr\", \n  messages = FALSE \n  ) +\n  scale_color_manual(values = col13_1) +\n  theme(axis.title.x = element_blank()) +\n  scale_y_continuous(limits = c(0, 1))\n\np2\n\n\n\n\n\n\n\n\n\nshow the code\nggbetweenstats(\n  data = joined_table,\n  x = haveKids, \n  y = joviality,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\nJoviality by EducationLevel: based on the statistical analysis conducted, the p-value was found to be less than the critical value of 0.05. Therefore, there is sufficient statistical evidence to reject the null hypothesis and conclude that there is a difference in median joviality between different education level groups.\nJoviality by Age/haveKids: the statistical analysis did not provide enough evidence to reject the null hypothesis. Therefore, we can conclude that there is no significant difference in median joviality for different age ranges or whether individuals have kids.\n\n\n\n3.3.3 Visualising Uncertainty\nWhile it may seem appealing to regard a point estimate such as the median as an accurate reflection of the true value of the data, it’s important to acknowledge that there may be inherent uncertainties associated with point estimates.\n\n\nshow the code\n# Create a gradient + interval plot to visualize the confidence intervals of mean joviality\njoined_table %>%\n  ggplot(aes(x = educationLevel, \n             y = joviality)) + \n  # Add a gradient plot with confidence intervals\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean joviality\",\n    subtitle = \"Gradient + interval plot\")"
  },
  {
    "objectID": "Take-home Exercise/Take-home Exercise 2/Take-home_Ex02.html",
    "href": "Take-home Exercise/Take-home Exercise 2/Take-home_Ex02.html",
    "title": "Take-home_Ex02",
    "section": "",
    "text": "The country of Oceanus has requested the assistance of FishEye International in identifying companies that may be involved in illegal, unreported, and unregulated (IUU) fishing. As part of this collaboration, FishEye’s analysts have been provided with import/export data related to Oceanus’ marine and fishing industries.\nTo facilitate their analysis, FishEye has transformed the trade data into a knowledge graph. During their analysis, FishEye analysts have found that node-link diagrams provide a valuable high-level overview of the knowledge graph. However, they are now seeking visualizations that offer more detailed insights into patterns involving entities within the knowledge graph.\n\nBased on FishEye’s previous experiences, they are aware that companies engaged in illegal fishing tend to cease their operations temporarily but often resume their activities under different names.\nThe objective of this exercise is to identify temporal patterns for individual entities and between entities in the knowledge graph FishEye created from trade records.\nThis exercise source is from: Mini-Challenge 2 task 1"
  },
  {
    "objectID": "Take-home Exercise/Take-home Exercise 2/Take-home_Ex02.html#install-r-packages-and-import-dataset",
    "href": "Take-home Exercise/Take-home Exercise 2/Take-home_Ex02.html#install-r-packages-and-import-dataset",
    "title": "Take-home_Ex02",
    "section": "2.1 Install R Packages and Import Dataset",
    "text": "2.1 Install R Packages and Import Dataset\nThe code chunk below uses pacman::p_load() to check if packages are installed. If they are, they will be launched into R. The packages installed are:\n\n\nshow the code\npacman::p_load(jsonlite, tidygraph, ggraph, visNetwork, lubridate, tidyverse,readxl,igraph)\n\n\njsonlite: A simple and robust JSON parser and generator for R.\ntidygraph: this package provides a tidy API for graph/network manipulation.\nggraph: ggiraph is a tool that allows you to create dynamic ggplot graphs.\nvisNetwork: an R package for network visualization, using vis.js javascript library.\nlubridate: an R package that makes it easier to work with dates and times.\ntidyverse: A collection of core packages designed for data science, used extensively for data preparation and wrangling.\nreadxl：An R package makes it easy to get data out of Excel and into R.\nigraph:igraph is a fast and open source library for the analysis of graphs or networks."
  },
  {
    "objectID": "Take-home Exercise/Take-home Exercise 2/Take-home_Ex02.html#data-introduction",
    "href": "Take-home Exercise/Take-home Exercise 2/Take-home_Ex02.html#data-introduction",
    "title": "Take-home_Ex02",
    "section": "2.2 Data Introduction",
    "text": "2.2 Data Introduction\nIn the code chunk below, fromJSON() of jsonlite package is used to import mc2_challenge_graph.json into R environment.\n\n\nshow the code\nmc2_data <- fromJSON(\"data/mc2_challenge_graph.json\")\n\n\nFor the purpose of this study, a directed multi-graph is provided. There are totally 34552 nodes and 5464092 directed edges.\nNode Attributes:\nid – Name of the company that originated (or received) the shipment.\nshpcountry – Country the company most often associated with when shipping.\nrcvcountry – Country the company most often associated with when receiving.\ndataset – Always ‘MC2’.\nEdge Attributes:\narrivaldate – Date the shipment arrived at port in YYYY-MM-DD format.\nhscode – Harmonized System code for the shipment. Can be joined with the hscodes table to get additional details.\nvalueofgoods_omu– Customs-declared value of the total shipment, in Oceanus Monetary Units (OMU).\nvolumeteu– The volume of the shipment in ‘Twenty-foot equivalent units’, roughly how many 20-foot standard containers would be required. (Actual number of containers may have been different as there are 20ft and 40ft standard containers and tankers that do not use containers)\nweightkg– The weight of the shipment in kilograms (if known).\ndataset– Always ‘MC2’.\ntype– Always ‘shipment’ for MC2.\ngenerated_by – Name of the program that generated the edge. (Only found on ‘bundle’ records.)\nNote: Some data provided by Oceanus was anonymized leading to some shipper and receiver names/countries being omitted. These are represented by numerical names in the graph."
  },
  {
    "objectID": "Take-home Exercise/Take-home Exercise 2/Take-home_Ex02.html#data-wrangling",
    "href": "Take-home Exercise/Take-home Exercise 2/Take-home_Ex02.html#data-wrangling",
    "title": "Take-home_Ex02",
    "section": "2.3 Data Wrangling",
    "text": "2.3 Data Wrangling\n\n2.3.1 Extract Nodes & Edges\nExtracting nodes : involves creating a tibble data frame called mc2_nodes from the mc2_data list object by using the select() function, which serves two purposes: selecting the required fields and re-organise the sequence of the fields.\n\n\nshow the code\nmc2_nodes <- as_tibble(mc2_data$nodes) %>%\n  select(id, shpcountry, rcvcountry)\n\n\n\n\n\n\n\n\nNote\n\n\n\nselect() is used not only to select the field needed but also to re-organise the sequent of the fields.\n\n\nExtracting Edges: The code chunk is used to extract edges data table from mc2_data list object and save the output in a tibble data frame object called mc2_edges.\n\n\nshow the code\nmc2_edges <- as_tibble(mc2_data$links) %>%\n  mutate(ArrivalDate = ymd(arrivaldate)) %>%\n  mutate(Year = year(ArrivalDate)) %>%\n  select(source, target, ArrivalDate, Year, hscode, valueofgoods_omu, \n         volumeteu, weightkg, valueofgoodsusd) %>% \n  distinct()\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nmutate() is used two times to create two derive fields.\n\nymd() of lubridate package is used to covert arrivaldate field from character data type into date data type.\nyear() of lubridate package is used to convert the values in ArrivalDate field into year values.\n\nselect() is used not only to select the field needed but also to re-organise the sequent of the fields.\n\n\n\n\n\n2.3.2 Data Preparation _ HScode\nThe Harmonized System is a standardized numerical method of classifying traded products. It is used by customs authorities around the world to identify products when assessing duties and taxes and for gathering statistics.\nIn the original dataframe, there are numerous HScodes that are unrelated to “Fishing”. To filter out observations specifically related to fishing, we utilize the grep function to select only those HScodes that begin with 301-308.\n\n\nshow the code\n# filters the dataframe mc2_edges hscode start with 301-308\nmc2_edges <- mc2_edges[grep(\"^30[1-8]\", mc2_edges$hscode), ]\n\n# Count each hscode frequency\nhscode_counts <- table(mc2_edges$hscode)\n\n# Sort by count from highest to lowest\nhscode_counts_sorted <- sort(hscode_counts, decreasing = TRUE)\n\n# Create a dataframe containing hscode and count\nhscode_counts_df <- data.frame(hscode = names(hscode_counts_sorted), count = hscode_counts_sorted, stringsAsFactors = FALSE)\n\n\n\n\n\n\n\n\nNote\n\n\n\n\ngrep(pattern, x) is a function that searches for a specified pattern (pattern) within a character vector (x).\ntable(x) is a function that creates a frequency table of the elements in the vector x. It counts the occurrences of each unique value and returns a table with the counts.\n\n-sort(x, decreasing = FALSE)is a function that sorts the elements in the vector x in ascending order.\n-data.frame(..., stringsAsFactors = FALSE) is a function that creates a data frame from the input arguments provided.\n\n\nAfter the compilation of the hscode_counts_df, it is important to determine the meaning of the HScode. Therefore, we proceed by reading the HScode list and employing the left_join function to establish a linkage between the item description and the hscode_counts_df data frame.\n\n\nshow the code\n# Remove the last zero in hscode\nhscode_counts_df$hscode <- sub(\"0$\", \"\", hscode_counts_df$hscode)\n\n# R an Excel file \"HScode\"\nHScode_list <- read_excel(\"data/HScode.xlsx\", sheet = 1)\n\n# Change the HS Code data type\nHScode_list$`HS Code` <- as.character(HScode_list$`HS Code`)\n\n# hscode_counts_df left join HScode_list to improt the HScode description\nmerged_data <- left_join(hscode_counts_df, select(HScode_list, -S.No.), by = c(\"hscode\" = \"HS Code\"))\n\n\n\n\n\n\n\n\nNote\n\n\n\nsub(pattern, replacement, x) is a function that replaces the first occurrence of a pattern (pattern) in a character vector (x) with a specified replacement string (replacement).\n`read_excel(file, sheet = 1)’ is a function that reads an Excel file (file) and imports the data from the specified sheet (sheet) into R.\n`left_join(x, y, by = c(“column_x” = “column_y”))’ is a function that performs a left join operation between two data frames (x and y) based on the specified column(s) to match (by).\n\n\nWe have summarized the top 6 most frequently occurring HScodes in the dataframe, along with their corresponding fish types based on the HScode descriptions. These HScodes and their associated fish types will serve as the starting point for our research.\n\nTop Frequency HScode\n\n\nHScode\nCount\nFish Type\n\n\n\n\n306170\n156204\nOther shrimps and prawns\n\n\n304620\n87340\nCatfish\n\n\n304610\n36615\nTilapias\n\n\n304710\n27231\nCod\n\n\n304750\n23926\nAlaska Pollack\n\n\n304810\n21433\nPacific salmonAtlantic salmon and Danube salmon\n\n\n\nThe HScode serves as an indicator of the product variety within each company. To analyze this, we have introduced a new variable called “HScode_type” that tallies the number of unique HScode values found in all transaction records for each company (node).\n\n\nshow the code\n# Create transitional dataframe to record all the company and corresponding Year\ntransition_data_HScode <- data.frame(\n  company = c(mc2_edges$source, mc2_edges$target),\n  HScode = c(mc2_edges$hscode, mc2_edges$ hscode)\n)\n\n# Aggregating companies & count each company's running year and running_ year_ Category\naggregate_data_HScode <- transition_data_HScode %>%\n  group_by(company) %>%\n  mutate(HScode_type = n_distinct(HScode)) %>%\n  distinct(company, HScode_type)%>%\n  mutate(HScode_category = cut(HScode_type, breaks = c(-Inf, 1, Inf), labels = c(\"<=1\",\">1\")))\n  \n# Filter the data \nfiltered_data <- subset(aggregate_data_HScode, HScode_type < 10)\n\nggplot(filtered_data, aes(x = HScode_type)) +\n  geom_bar(fill = '#808de8') +\n  labs(x = \"HScode_type\", y = \"Count\") +\n  ggtitle(\"Bar Chart of HScode_type (<10)\") +\n  scale_x_continuous(breaks = 1:9, labels = 1:9) +\n  theme(axis.title.y = element_text(angle = 0),\n        axis.ticks.x = element_blank(),\n        panel.background = element_blank(),\n        axis.line = element_line(color = 'bisque3'),\n        plot.subtitle = element_text(color = \"dimgrey\", size = 12, face = \"bold\", hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nc()is used to concatenate or combine multiple values or objects into a single vector:\n\nc(mc2_edges\\(source, mc2_edges\\)target) creates a vector that concatenates the values of the source column and the target column from the mc2_edges data frame. This vector contains all the company names.\nc(mc2_edges\\(hscode, mc2_edges\\)hscode) creates a vector that concatenates the values of the hscode column from the mc2_edges data frame. This vector contains all the corresponding hscode for each company.\n\ngroup_by() is used to aggregate values by company. mutate() creates a new column called HScode_type, which contains the number of distinct HScode values for each company.distinct() keeps only the distinct combinations of company and HScode_type in the transition_data_HScode data frame. cut()categorizes the HScode_type values into two categories: “<=1” and “>1” based on the breakpoints.\nsubset(x, subset) is a function used to subset a data frame (x) based on specified conditions (subset).\n\n\n\nIn order to gain a holistic understanding of the distribution of companies with different product varieties, we have generated a bar chart depicting the frequency of HScode_type values below 10. Upon examining the bar chart, we observe a substantial proportion of companies having an HScode_type value of 1 compared to other HScode_type values.\n\n\n2.3.3 Data Preparation _ Running Year Category\nIn light of the circumstance where companies engaged in illegal fishing activities might cease operations but subsequently resume their activities under a different corporate identity, it is noteworthy that companies with shorter running years possess a higher likelihood of engaging in illicit behaviors.so we create transition_data to count each company’s running years.\n\n\nshow the code\n# Create transitional dataframe to record all the company and corresponding Year\ntransition_data_Year <- data.frame(\n  company = c(mc2_edges$source, mc2_edges$target),\n  Year = c(mc2_edges$Year, mc2_edges$Year)\n)\n\n# Aggregating companies & count each company's running year and running_ year_ Category\naggregate_data_Year <- transition_data_Year %>%\n  group_by(company) %>%\n  mutate(running_year = n_distinct(Year)) %>%\n  distinct(company, running_year) %>%\n  mutate(running_year_category = cut(running_year, breaks = c(-Inf, 3, Inf), labels = c(\"<=3\",\">3\")))\n\n\nTo facilitate analysis, we have categorized the running years into distinct intervals, namely “<=3” and “>3”, to assess the stability of the companies. Within these intervals:\n\n“<=3” category represents companies with lower stability\n“>3” years category signifies a relatively high level of stability.\n\nIt is worth noting that companies with lower stability, falling within the “<=3” category, tend to exhibit a higher likelihood of being associated with suspected illegal activities.\n\n\nshow the code\n# Create a barchart of running_year distribution with adjusted x-axis labels\nggplot(aggregate_data_Year, aes(x = running_year)) +\n  geom_bar(fill = '#808de8') +\n  labs(x = \"Running Year\", y = \"Count\") +\n  ggtitle(\"Distribution of Running Year\") +\n  scale_x_continuous(breaks = 1:7, labels = 1:7) +\n  theme(axis.title.y = element_text(angle = 0),\n        axis.ticks.x = element_blank(),\n        panel.background = element_blank(),\n        axis.line = element_line(color = 'bisque3'),\n        plot.subtitle = element_text(color = \"dimgrey\", size = 12, face = \"bold\", hjust = 0.5))\n\n\n\n\n\nThe barchart depicting the “Distribution of Running Year” reveals a notable observation:\n\nA considerable proportion of companies, exceeding 4000 in number, have a running year of merely one year.\nAs the running year increases, there is a gradual decline in the number of companies.\nHowever, it is intriguing to note that there exists a substantial count of over 1000 companies that have been operating for seven years, surpassing the counts of companies with three, four, five, and six running years.\n\n\n\n2.3.4 Data Preparation _ Betweenness/In-degree/Out-degree\nCentrality is a significant characteristic in network analysis. In this section, we will compute three important centrality measures for each node: betweenness centrality, in-degree centrality, and out-degree centrality.\nBetweenness centrality: This measure quantifies the extent to which a node acts as a bridge or mediator in the network. It calculates the fraction of shortest paths between all pairs of nodes that pass through a particular node.\nIn-degree centrality: This measure focuses on the number of incoming edges or connections to a node. It signifies the degree to which a node receives interactions or dependencies from other nodes in the network.\nOut-degree centrality: This measure pertains to the number of outgoing edges or connections from a node. It indicates the degree to which a node initiates interactions or dependencies with other nodes in the network.\nThrough the computation of these centrality measures, we can gain insights into the structural importance and influence of each node within the network, enabling us to better understand the dynamics and functioning of the network as a whole.\n\n\nshow the code\n# Aggregating edges data\nmc2_all_edges_aggregated <- mc2_edges %>%\n  group_by(from = source, to = target, hscode, Year) %>%\n  summarise(weights = n()) %>%\n  filter(from != to) %>%\n  filter(weights > 20) %>%\n  ungroup()\n\n\n\n\n\n\n\n\nNote\n\n\n\n\ngroup_by() is used to aggregate values by source, target, hscode, Year.\nsummarise() and n() are used to count the aggregated records.\nfilter() is then used to perform two selections to select all records whereby source are not equal to target to select all records whereby the values of their weights field are greater than 20\n\n\n\n\n\nshow the code\n# Extracting unique node IDs\nid1_all <- mc2_all_edges_aggregated %>%\n  select(from) %>%\n  rename(id = from)\nid2_all <- mc2_all_edges_aggregated %>%\n  select(to) %>%\n  rename(id = to)\nmc2_all_nodes_extracted <- rbind(id1_all, id2_all) %>%\n  distinct()\n\nmc2_all_graph <- tbl_graph(nodes = mc2_all_nodes_extracted,\n                       edges = mc2_all_edges_aggregated,\n                       directed = TRUE)\n\n\n# Calculate betweenness centrality\nbetweenness_centrality <- betweenness(mc2_all_graph)\n\n# Calculate in-degree centrality\nin_degree_centrality <- degree(mc2_all_graph, mode = \"in\")\n\n# Calculate out-degree centrality\nout_degree_centrality <- degree(mc2_all_graph, mode = \"out\")\n\n# Convert the node attributes and ID to a dataframe\nnode_data <- data.frame(\n  ID = V(mc2_all_graph)$id,\n  Betweenness = betweenness_centrality,\n  In_Degree = in_degree_centrality,\n  Out_Degree = out_degree_centrality\n)\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nrbind()combines the id1_all and id2_all data frames vertically, we get a single data frame mc2_all_nodes_extracted with all the distinct node IDs.\nbetweenness()calculates the betweenness centrality for each node.\ndegree(, mode = \"in\")calculates the in-degree centrality for each node.\ndegree(, mode = \"out\")calculates the out-degree centrality for each node.\n\n\n\nBased on the node centrality table, we can classify the nodes into three distinct groups:\nWholesaler: Nodes exhibiting non-zero values in betweenness centrality, in-degree centrality, and out-degree centrality. These nodes demonstrate a comprehensive pattern of connectivity within the network, indicating their involvement in multiple fish trading flows. We can infer that these nodes operate as wholesalers, facilitating the buying and selling of fish products.\nBuyer: Nodes displaying non-zero values in in-degree centrality, while both betweenness centrality and out-degree centrality possess zero values. These nodes primarily act as recipients or buyers within the network, buying fish products from other nodes.\nSupplier: Nodes featuring non-zero values in out-degree centrality, while both betweenness centrality and in-degree centrality exhibit zero values. These nodes operate as suppliers within the network, selling fish product to other nodes.\n\n\nshow the code\nnode_data$company_label <- NA  # Create a new column for storing company_ Label\n\n# Assign values to company_label based on conditions\nnode_data$company_label[node_data$Betweenness != 0 & node_data$Betweenness > 20] <- \"wholesaler_high\"\nnode_data$company_label[node_data$Betweenness != 0 & node_data$Betweenness <= 20 & node_data$Betweenness >= 10] <- \"wholesaler_medium\"\nnode_data$company_label[node_data$Betweenness != 0 & node_data$Betweenness < 10] <- \"wholesaler_low\"\n\nnode_data$company_label[node_data$Betweenness == 0 & node_data$Out_Degree == 0 & node_data$In_Degree != 0 & node_data$In_Degree > 150] <- \"buyer_high\"\nnode_data$company_label[node_data$Betweenness == 0 & node_data$Out_Degree == 0 & node_data$In_Degree != 0 & node_data$In_Degree <= 150 & node_data$In_Degree >= 50] <- \"buyer_mediu m\"\nnode_data$company_label[node_data$Betweenness == 0 & node_data$Out_Degree == 0 & node_data$In_Degree != 0 & node_data$In_Degree < 50] <- \"buyer_low\"\n\nnode_data$company_label[node_data$Betweenness == 0 & node_data$In_Degree == 0 & node_data$Out_Degree != 0 & node_data$Out_Degree > 50] <- \"supplier_high\"\nnode_data$company_label[node_data$Betweenness == 0 & node_data$In_Degree == 0 & node_data$Out_Degree != 0 & node_data$Out_Degree <= 50 & node_data$Out_Degree >= 20] <- \"supplier_medium\"\nnode_data$company_label[node_data$Betweenness == 0 & node_data$In_Degree == 0 & node_data$Out_Degree != 0 & node_data$Out_Degree < 20] <- \"supplier_low\"\n\n# Calculate the normalization of Betweenness, In_Degree, and Out_Degree\nnormalized_betweenness <- (node_data$Betweenness - min(node_data$Betweenness)) / (max(node_data$Betweenness) - min(node_data$Betweenness))\nnormalized_in_degree <- (node_data$In_Degree - min(node_data$In_Degree)) / (max(node_data$In_Degree) - min(node_data$In_Degree))\nnormalized_out_degree <- (node_data$Out_Degree - min(node_data$Out_Degree)) / (max(node_data$Out_Degree) - min(node_data$Out_Degree))\n\n\n# Add the 'size' column based on conditions\nnode_data$size_all <- normalized_betweenness + normalized_in_degree + normalized_out_degree\n\n# identification based on betweenness/in-degree/out-degree centrality\nnode_data$company_category <- ifelse(node_data$Betweenness != 0, \"Wholesaler\",\n                         ifelse(node_data$Out_Degree != 0, \"Supplier\",\n                                ifelse(node_data$In_Degree != 0,\"Buyer\", NA)))\n\n\nTo comprehend the range of centrality within each model, we further divide the nodes into high, medium, and low levels based on their centrality scores, and subsequently generate box plots to visualize the distribution of centrality scores within each group.\n\n\nshow the code\nlibrary(ggplot2)\n\n# Create a custom color vector\ncolors <- c(\"#FF6F61\", \"#6B5B95\", \"#88B04B\", \"#F7CAC9\", \"#92A8D1\", \"#955251\", \"#B565A7\", \"#009B77\", \"#DD4124\")\n\n# Extract the required data\nboxplot_data <- node_data %>%\n  select(company_label, Betweenness, In_Degree, Out_Degree) %>%\n  pivot_longer(cols = -company_label, names_to = \"variable\", values_to = \"value\")\n\n# Plot the boxplot\nboxplot_plot <- ggplot(boxplot_data, aes(x = company_label, y = value, fill = company_label)) +\n  geom_boxplot() +\n  facet_wrap(~ variable, scales = \"free_y\", ncol = 1) +\n  theme_minimal() +\n  labs(x = \"company_label\", y = \"\") +\n  coord_flip() +\n  scale_fill_manual(values = colors)\n\nboxplot_plot\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n-select()selects specific columns (company_label, Betweenness, In_Degree, Out_Degree) from the node_data data frame.\n\npivot_longer()reshapes the data frame from a wide format to a long format. It takes all columns except for company_label and pivots them into two new columns: variable and value.\n\n\n\nFrom the boxplot analysis, the following observations can be made:\n- Only nodes categorized as wholesalers exhibit non-zero values in betweenness centrality. The range of betweenness centrality scores for wholesalers falls between 24 and 51.\n- Nodes categorized as suppliers have a zero in-degree centrality. Nodes categorized as buyers have a higher in-degree centrality compared to wholesalers within the same level. For instance, the in-degree centrality range for high-level buyers is from 192 to 380, whereas the in-degree centrality range for high-level wholesalers is from 3 to 111.\n- Nodes categorized as buyers have a zero in-degree centrality. Nodes categorized as suppliers have a higher out-degree centrality compared to wholesalers within the same level. For example, the out-degree centrality range for high-level suppliers is from 53 to 94, whereas the out-degree centrality range for high-level wholesalers is from 1 to 39.\nFor the subsequent analysis, we will simplify the node categorization into three basic models: wholesalers, buyers, and suppliers, in order to avoid excessive grouping and maintain focus on the fundamental classification.\n\n\n2.3.5 Data Preparation _ Data Feature Extraction\nIn this section, we will create a new data frame called “node_data_feature” to consolidate the features obtained from previous analyses. This data frame will incorporate information regarding the nodes’ running_year_category and company_label (wholesaler, supplier, or buyer), thereby enabling further subgrouping of the nodes based on these features.\n\n\nshow the code\nnode_data_feature <- node_data %>%\n  left_join(aggregate_data_Year %>% distinct(company, running_year_category), by = c(\"ID\" = \"company\")) \n\n\n\n\n\n\n\n\nNote\n\n\n\nBy left_join(),node_data_feature includes the original columns from the node_data data frame, as well as the additional columns “running_year_category”.\n\n\n\n\nshow the code\n# Create Company_group column and assign values based on conditions\nnode_data_feature$Company_group <- ifelse(\n  node_data_feature$running_year_category == \"<=3\" & node_data_feature$company_category == \"Supplier\",\n  \"Unstable_Supplier\",\n    ifelse(\n      node_data_feature$running_year_category == \">3\" & node_data_feature$company_category == \"Supplier\",\n      \"Stable_Supplier\",\n        ifelse(\n          node_data_feature$running_year_category == \"<=3\" & node_data_feature$company_category == \"Buyer\",\n          \"Unstable_Buyer\",\n            ifelse(\n              node_data_feature$running_year_category == \">3\" & node_data_feature$company_category == \"Buyer\",\n              \"Stable_Buyer\",\n                  ifelse(\n                    node_data_feature$running_year_category == \"<=3\" & node_data_feature$company_category == \"Wholesaler\",\n                    \"Unstable_Wholesaler\",\n                    ifelse(\n                      node_data_feature$running_year_category == \">3\" & node_data_feature$company_category == \"Wholesaler\",\n                      \"Stable_Wholesaler\",\n                        \"Unknown\"  # Handling unmatched situations can be changed according to actual needs\n                      )\n                    )\n                  )\n                )\n              )\n            )\n\n\n\n\nshow the code\n# Create a named vector that specifies the color corresponding to each group\ngroup_colors <- c(\"Unstable_Supplier\" = \"lightpink1\",\n                  \n                  \"Stable_Supplier\" = \"lightpink2\",\n                 \n                  \"Unstable_Buyer\" = \"cadetblue3\",\n       \n                  \"Stable_Buyer\" = \"cadetblue\",\n               \n                  \"Unstable_Wholesaler\" = \"grey\",\n                \n                  \"Stable_Wholesaler\" = \"grey60\")\n\n# Count Company_ Number of groups per category\ngroup_counts <- table(node_data_feature$Company_group)\n\n# Convert count results into dataframe\ngroup_counts_df <- data.frame(Company_group = names(group_counts), Frequency = as.numeric(group_counts))\n\n# Draw a bar chart for the company group\ngroup_counts_df$Company_group <- reorder(group_counts_df$Company_group, group_counts_df$Frequency)\nggplot(group_counts_df, aes(x = Company_group, y = Frequency, fill = Company_group)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = group_colors) +\n  labs(x = \"Company Group\", y = \"Count\") +\n  ggtitle(\"Count of Company Groups\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n-reorder() is used to reorder the levels of the Company_group factor in the group_counts_df dataframe based on the Frequency variable.\n-coord_flip() is used to flip the x and y axes, resulting in a horizontal bar chart.\n\n\nTo visualize the distribution of companies within these groups, a bar chart is plotted based on the company group. It is evident from the chart that the “Stable_Supplier” group exhibits the highest percentage, followed by the “Stable_Buyer” group. These two groups demonstrate noticeably higher percentages compared to the other groups, indicating their prominence within the network. There is no unstable_wholesaler in the dataset."
  },
  {
    "objectID": "Take-home Exercise/Take-home Exercise 2/Take-home_Ex02.html#interactive-network-graph-with-visnetwork",
    "href": "Take-home Exercise/Take-home Exercise 2/Take-home_Ex02.html#interactive-network-graph-with-visnetwork",
    "title": "Take-home_Ex02",
    "section": "3.1 Interactive Network Graph with visNetwork",
    "text": "3.1 Interactive Network Graph with visNetwork\nIn this section, a network plot is generated for a subset of nodes focusing on those with a specific HScode (306170). To manage the large volume of nodes, a filter condition based on the Year variable is applied, enabling the separation of networks for different years.\nIn the network plot, each node is assigned a color based on its company_group, allowing for a clear visualization of its distinctive features within the network. This coloring scheme facilitates the identification and interpretation of the nodes’ characteristics and facilitates the analysis of their interactions and connections.\n\n2028202920302031203220332034\n\n\n\n\nshow the code\n# Aggregating and filtering edges data\nmc2_edges_aggregated <- mc2_edges %>%\n  filter(hscode == \"306170\"& Year == \"2028\") %>%\n  group_by(from = source, to = target, hscode, Year) %>%\n  summarise(weights = n()) %>%\n  filter(from != to) %>%\n  filter(weights > 20) %>%\n  ungroup()\n\n# Extracting unique node IDs\nid1 <- mc2_edges_aggregated %>%\n  select(from) %>%\n  rename(id = from)\nid2 <- mc2_edges_aggregated %>%\n  select(to) %>%\n  rename(id = to)\nmc2_nodes_extracted <- rbind(id1, id2) %>%\n  distinct()\n\n# Joining extracted nodes with node_data_feature\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  left_join(node_data_feature %>% distinct(ID, size_all, Company_group), by = c(\"id\" = \"ID\")) \n\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  rename(group = Company_group)\n\n# Node size adjustment\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  rename(size = size_all) %>%\n  mutate(size = size * 100)\n\n# Plot the Network\ng <- visNetwork(nodes = mc2_nodes_extracted, edges = mc2_edges_aggregated, height = \"500px\", width = \"100%\") %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visNodes(color = group_colors) %>%\n  visEdges(arrows = 'to') %>%\n  visEdges(color = list(highlight = \"lightgray\")) %>%\n  visOptions(selectedBy = \"group\",\n             highlightNearest = list(enabled = TRUE,\n                                     degree = 1,\n                                     hover = TRUE,\n                                     labelOnly = TRUE),\n             nodesIdSelection = TRUE) %>%\n  visGroups(groupname = \"Unstable_Supplier\", color = \"yellow\") %>%    \n  visGroups(groupname = \"Stable_Supplier\", color = \"grey\") %>%\n  visGroups(groupname = \"Unstable_Buyer\", color = \"orange\") %>%  \n  visGroups(groupname = \"Stable_Buyer\", color = \"cadetblue\") %>%  \n  visGroups(groupname = \"Unstable_Wholesaler\", color = \"yellow\") %>% \n  visGroups(groupname = \"Stable_Wholesaler\", color = \"green\") %>% \n\n  visLegend() %>%\n  visInteraction(navigationButtons = TRUE) %>%\n  visLayout(randomSeed = 123)\ng\n\n\n\n\n\n\n\n\n\n\n\nshow the code\n# Aggregating and filtering edges data\nmc2_edges_aggregated <- mc2_edges %>%\n  filter(hscode == \"306170\"& Year == \"2029\") %>%\n  group_by(from = source, to = target, hscode, Year) %>%\n  summarise(weights = n()) %>%\n  filter(from != to) %>%\n  filter(weights > 20) %>%\n  ungroup()\n\n# Extracting unique node IDs\nid1 <- mc2_edges_aggregated %>%\n  select(from) %>%\n  rename(id = from)\nid2 <- mc2_edges_aggregated %>%\n  select(to) %>%\n  rename(id = to)\nmc2_nodes_extracted <- rbind(id1, id2) %>%\n  distinct()\n\n# Joining extracted nodes with node_data_feature\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  left_join(node_data_feature %>% distinct(ID, size_all, Company_group), by = c(\"id\" = \"ID\")) \n\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  rename(group = Company_group)\n\n# Node size adjustment\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  rename(size = size_all) %>%\n  mutate(size = size * 100)\n\n# Plot the Network\ng <- visNetwork(nodes = mc2_nodes_extracted, edges = mc2_edges_aggregated, height = \"500px\", width = \"100%\") %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visNodes(color = group_colors) %>%\n  visEdges(arrows = 'to') %>%\n  visEdges(color = list(highlight = \"lightgray\")) %>%\n  visOptions(selectedBy = \"group\",\n             highlightNearest = list(enabled = TRUE,\n                                     degree = 1,\n                                     hover = TRUE,\n                                     labelOnly = TRUE),\n             nodesIdSelection = TRUE) %>%\n  visGroups(groupname = \"Unstable_Supplier\", color = \"yellow\") %>%    \n  visGroups(groupname = \"Stable_Supplier\", color = \"grey\") %>%\n  visGroups(groupname = \"Unstable_Buyer\", color = \"orange\") %>%  \n  visGroups(groupname = \"Stable_Buyer\", color = \"cadetblue\") %>%  \n  visGroups(groupname = \"Unstable_Wholesaler\", color = \"yellow\") %>% \n  visGroups(groupname = \"Stable_Wholesaler\", color = \"green\") %>% \n\n  visLegend() %>%\n  visInteraction(navigationButtons = TRUE) %>%\n  visLayout(randomSeed = 123)\ng\n\n\n\n\n\n\n\n\n\n\n\nshow the code\n# Aggregating and filtering edges data\nmc2_edges_aggregated <- mc2_edges %>%\n  filter(hscode == \"306170\"& Year == \"2030\") %>%\n  group_by(from = source, to = target, hscode, Year) %>%\n  summarise(weights = n()) %>%\n  filter(from != to) %>%\n  filter(weights > 20) %>%\n  ungroup()\n\n# Extracting unique node IDs\nid1 <- mc2_edges_aggregated %>%\n  select(from) %>%\n  rename(id = from)\nid2 <- mc2_edges_aggregated %>%\n  select(to) %>%\n  rename(id = to)\nmc2_nodes_extracted <- rbind(id1, id2) %>%\n  distinct()\n\n# Joining extracted nodes with node_data_feature\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  left_join(node_data_feature %>% distinct(ID, size_all, Company_group), by = c(\"id\" = \"ID\")) \n\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  rename(group = Company_group)\n\n# Node size adjustment\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  rename(size = size_all) %>%\n  mutate(size = size * 100)\n\n# Plot the Network\ng <- visNetwork(nodes = mc2_nodes_extracted, edges = mc2_edges_aggregated, height = \"500px\", width = \"100%\") %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visNodes(color = group_colors) %>%\n  visEdges(arrows = 'to') %>%\n  visEdges(color = list(highlight = \"lightgray\")) %>%\n  visOptions(selectedBy = \"group\",\n             highlightNearest = list(enabled = TRUE,\n                                     degree = 1,\n                                     hover = TRUE,\n                                     labelOnly = TRUE),\n             nodesIdSelection = TRUE) %>%\n  visGroups(groupname = \"Unstable_Supplier\", color = \"yellow\") %>%    \n  visGroups(groupname = \"Stable_Supplier\", color = \"grey\") %>%\n  visGroups(groupname = \"Unstable_Buyer\", color = \"orange\") %>%  \n  visGroups(groupname = \"Stable_Buyer\", color = \"cadetblue\") %>%  \n  visGroups(groupname = \"Unstable_Wholesaler\", color = \"yellow\") %>% \n  visGroups(groupname = \"Stable_Wholesaler\", color = \"green\") %>% \n\n  visLegend() %>%\n  visInteraction(navigationButtons = TRUE) %>%\n  visLayout(randomSeed = 123)\ng\n\n\n\n\n\n\n\n\n\n\n\nshow the code\n# Aggregating and filtering edges data\nmc2_edges_aggregated <- mc2_edges %>%\n  filter(hscode == \"306170\"& Year == \"2031\") %>%\n  group_by(from = source, to = target, hscode, Year) %>%\n  summarise(weights = n()) %>%\n  filter(from != to) %>%\n  filter(weights > 20) %>%\n  ungroup()\n\n# Extracting unique node IDs\nid1 <- mc2_edges_aggregated %>%\n  select(from) %>%\n  rename(id = from)\nid2 <- mc2_edges_aggregated %>%\n  select(to) %>%\n  rename(id = to)\nmc2_nodes_extracted <- rbind(id1, id2) %>%\n  distinct()\n\n# Joining extracted nodes with node_data_feature\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  left_join(node_data_feature %>% distinct(ID, size_all, Company_group), by = c(\"id\" = \"ID\")) \n\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  rename(group = Company_group)\n\n# Node size adjustment\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  rename(size = size_all) %>%\n  mutate(size = size * 100)\n\n# Plot the Network\ng <- visNetwork(nodes = mc2_nodes_extracted, edges = mc2_edges_aggregated, height = \"500px\", width = \"100%\") %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visNodes(color = group_colors) %>%\n  visEdges(arrows = 'to') %>%\n  visEdges(color = list(highlight = \"lightgray\")) %>%\n  visOptions(selectedBy = \"group\",\n             highlightNearest = list(enabled = TRUE,\n                                     degree = 1,\n                                     hover = TRUE,\n                                     labelOnly = TRUE),\n             nodesIdSelection = TRUE) %>%\n  visGroups(groupname = \"Unstable_Supplier\", color = \"yellow\") %>%    \n  visGroups(groupname = \"Stable_Supplier\", color = \"grey\") %>%\n  visGroups(groupname = \"Unstable_Buyer\", color = \"orange\") %>%  \n  visGroups(groupname = \"Stable_Buyer\", color = \"cadetblue\") %>%  \n  visGroups(groupname = \"Unstable_Wholesaler\", color = \"yellow\") %>% \n  visGroups(groupname = \"Stable_Wholesaler\", color = \"green\") %>% \n\n  visLegend() %>%\n  visInteraction(navigationButtons = TRUE) %>%\n  visLayout(randomSeed = 123)\ng\n\n\n\n\n\n\n\n\n\n\n\nshow the code\n# Aggregating and filtering edges data\nmc2_edges_aggregated <- mc2_edges %>%\n  filter(hscode == \"306170\"& Year == \"2032\") %>%\n  group_by(from = source, to = target, hscode, Year) %>%\n  summarise(weights = n()) %>%\n  filter(from != to) %>%\n  filter(weights > 20) %>%\n  ungroup()\n\n# Extracting unique node IDs\nid1 <- mc2_edges_aggregated %>%\n  select(from) %>%\n  rename(id = from)\nid2 <- mc2_edges_aggregated %>%\n  select(to) %>%\n  rename(id = to)\nmc2_nodes_extracted <- rbind(id1, id2) %>%\n  distinct()\n\n# Joining extracted nodes with node_data_feature\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  left_join(node_data_feature %>% distinct(ID, size_all, Company_group), by = c(\"id\" = \"ID\")) \n\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  rename(group = Company_group)\n\n# Node size adjustment\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  rename(size = size_all) %>%\n  mutate(size = size * 100)\n\n# Plot the Network\ng <- visNetwork(nodes = mc2_nodes_extracted, edges = mc2_edges_aggregated, height = \"500px\", width = \"100%\") %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visNodes(color = group_colors) %>%\n  visEdges(arrows = 'to') %>%\n  visEdges(color = list(highlight = \"lightgray\")) %>%\n  visOptions(selectedBy = \"group\",\n             highlightNearest = list(enabled = TRUE,\n                                     degree = 1,\n                                     hover = TRUE,\n                                     labelOnly = TRUE),\n             nodesIdSelection = TRUE) %>%\n  visGroups(groupname = \"Unstable_Supplier\", color = \"yellow\") %>%    \n  visGroups(groupname = \"Stable_Supplier\", color = \"grey\") %>%\n  visGroups(groupname = \"Unstable_Buyer\", color = \"orange\") %>%  \n  visGroups(groupname = \"Stable_Buyer\", color = \"cadetblue\") %>%  \n  visGroups(groupname = \"Unstable_Wholesaler\", color = \"yellow\") %>% \n  visGroups(groupname = \"Stable_Wholesaler\", color = \"green\") %>% \n\n  visLegend() %>%\n  visInteraction(navigationButtons = TRUE) %>%\n  visLayout(randomSeed = 123)\ng\n\n\n\n\n\n\n\n\n\n\n\nshow the code\n# Aggregating and filtering edges data\nmc2_edges_aggregated <- mc2_edges %>%\n  filter(hscode == \"306170\"& Year == \"2033\") %>%\n  group_by(from = source, to = target, hscode, Year) %>%\n  summarise(weights = n()) %>%\n  filter(from != to) %>%\n  filter(weights > 20) %>%\n  ungroup()\n\n# Extracting unique node IDs\nid1 <- mc2_edges_aggregated %>%\n  select(from) %>%\n  rename(id = from)\nid2 <- mc2_edges_aggregated %>%\n  select(to) %>%\n  rename(id = to)\nmc2_nodes_extracted <- rbind(id1, id2) %>%\n  distinct()\n\n# Joining extracted nodes with node_data_feature\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  left_join(node_data_feature %>% distinct(ID, size_all, Company_group), by = c(\"id\" = \"ID\")) \n\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  rename(group = Company_group)\n\n# Node size adjustment\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  rename(size = size_all) %>%\n  mutate(size = size * 100)\n\n# Plot the Network\ng <- visNetwork(nodes = mc2_nodes_extracted, edges = mc2_edges_aggregated, height = \"500px\", width = \"100%\") %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visNodes(color = group_colors) %>%\n  visEdges(arrows = 'to') %>%\n  visEdges(color = list(highlight = \"lightgray\")) %>%\n  visOptions(selectedBy = \"group\",\n             highlightNearest = list(enabled = TRUE,\n                                     degree = 1,\n                                     hover = TRUE,\n                                     labelOnly = TRUE),\n             nodesIdSelection = TRUE) %>%\n  visGroups(groupname = \"Unstable_Supplier\", color = \"yellow\") %>%    \n  visGroups(groupname = \"Stable_Supplier\", color = \"grey\") %>%\n  visGroups(groupname = \"Unstable_Buyer\", color = \"orange\") %>%  \n  visGroups(groupname = \"Stable_Buyer\", color = \"cadetblue\") %>%  \n  visGroups(groupname = \"Unstable_Wholesaler\", color = \"yellow\") %>% \n  visGroups(groupname = \"Stable_Wholesaler\", color = \"green\") %>% \n\n  visLegend() %>%\n  visInteraction(navigationButtons = TRUE) %>%\n  visLayout(randomSeed = 123)\ng\n\n\n\n\n\n\n\n\n\n\n\nshow the code\n# Aggregating and filtering edges data\nmc2_edges_aggregated <- mc2_edges %>%\n  filter(hscode == \"306170\"& Year == \"2034\") %>%\n  group_by(from = source, to = target, hscode, Year) %>%\n  summarise(weights = n()) %>%\n  filter(from != to) %>%\n  filter(weights > 20) %>%\n  ungroup()\n\n# Extracting unique node IDs\nid1 <- mc2_edges_aggregated %>%\n  select(from) %>%\n  rename(id = from)\nid2 <- mc2_edges_aggregated %>%\n  select(to) %>%\n  rename(id = to)\nmc2_nodes_extracted <- rbind(id1, id2) %>%\n  distinct()\n\n# Joining extracted nodes with node_data_feature\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  left_join(node_data_feature %>% distinct(ID, size_all, Company_group), by = c(\"id\" = \"ID\")) \n\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  rename(group = Company_group)\n\n# Node size adjustment\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  rename(size = size_all) %>%\n  mutate(size = size * 100)\n\n# Plot the Network\ng <- visNetwork(nodes = mc2_nodes_extracted, edges = mc2_edges_aggregated, height = \"500px\", width = \"100%\") %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visNodes(color = group_colors) %>%\n  visEdges(arrows = 'to') %>%\n  visEdges(color = list(highlight = \"lightgray\")) %>%\n  visOptions(selectedBy = \"group\",\n             highlightNearest = list(enabled = TRUE,\n                                     degree = 1,\n                                     hover = TRUE,\n                                     labelOnly = TRUE),\n             nodesIdSelection = TRUE) %>%\n  visGroups(groupname = \"Unstable_Supplier\", color = \"yellow\") %>%    \n  visGroups(groupname = \"Stable_Supplier\", color = \"grey\") %>%\n  visGroups(groupname = \"Unstable_Buyer\", color = \"orange\") %>%  \n  visGroups(groupname = \"Stable_Buyer\", color = \"cadetblue\") %>%  \n  visGroups(groupname = \"Unstable_Wholesaler\", color = \"yellow\") %>% \n  visGroups(groupname = \"Stable_Wholesaler\", color = \"green\") %>% \n\n  visLegend() %>%\n  visInteraction(navigationButtons = TRUE) %>%\n  visLayout(randomSeed = 123)\ng\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nselectedBy = “group”: Specifies that nodes can be selected by their group attribute. highlightNearest: Configures the highlighting of nearest nodes.\nenabled = TRUE: Enables the highlighting of nearest nodes.\ndegree = 1: Specifies the degree of nearest nodes to be highlighted. Here, it is set to 1, meaning only the immediate neighboring nodes will be highlighted.\nhover = TRUE: Enables highlighting on hover.\nlabelOnly = TRUE: Specifies that only the label of the node will be highlighted.\nnodesIdSelection = TRUE: Allows selecting nodes by their ID.\nVisGroup() is used to set the node color."
  },
  {
    "objectID": "Take-home Exercise/Take-home Exercise 2/Take-home_Ex02.html#ego-network-for-key-node",
    "href": "Take-home Exercise/Take-home Exercise 2/Take-home_Ex02.html#ego-network-for-key-node",
    "title": "Take-home_Ex02",
    "section": "3.2 Ego-Network for Key Node",
    "text": "3.2 Ego-Network for Key Node\nFor further analysis of key node connections, an ego-net approach is employed to examine the connections of a specific node, namely “hǎi dǎn Corporation Wharf”, which has been identified based on the previous section’s analysis. The selection of this node is driven by its large in-degree centrality, suggesting potential significance and relevance in the network structure. By focusing on the ego-net of “hǎi dǎn Corporation Wharf”, we can gain deeper insights into its immediate connections and study its specific role and influence within the network.\n\n2028202920302031203220332034\n\n\n\n\nshow the code\n# Aggregating and filtering edges data\nmc2_edges_aggregated <- mc2_edges %>%\n  filter(hscode == \"306170\"& Year == \"2028\") %>%\n  group_by(from = source, to = target, hscode, Year) %>%\n  summarise(weights = n()) %>%\n  filter(from != to) %>%\n  filter(weights > 20) %>%\n  ungroup()\n\n# Extracting unique node IDs\nid1 <- mc2_edges_aggregated %>%\n  select(from) %>%\n  rename(id = from)\nid2 <- mc2_edges_aggregated %>%\n  select(to) %>%\n  rename(id = to)\nmc2_nodes_extracted <- rbind(id1, id2) %>%\n  distinct()\n\n# Joining extracted nodes with company data to add running_year_category information\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  left_join(node_data_feature %>% distinct(ID, size_all, Company_group), by = c(\"id\" = \"ID\")) \n\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  rename(group = Company_group)\n\n\nego_edges <- mc2_edges_aggregated %>%\n  filter(from == \"hǎi dǎn Corporation Wharf\" | to == \"hǎi dǎn Corporation Wharf\")\n\n# Extract unique node IDs from ego_edges\nego_node_ids <- unique(c(ego_edges$from, ego_edges$to))\n\n# Filter ego_nodes using the unique node IDs\nego_nodes <- mc2_nodes_extracted %>%\n  filter(id %in% ego_node_ids) %>%\n  mutate(node_id = row_number())\n\n# Set the node size\nego_nodes <- ego_nodes %>%\n  rename(size = size_all) %>%\n  mutate(size = size * 100)\n\n\n# Update ego_edges with the corresponding node IDs\nego_edges <- ego_edges %>%\n  left_join(ego_nodes %>% select(id, node_id), by = c(\"from\" = \"id\")) %>%\n  rename(from_node = node_id) %>%\n  left_join(ego_nodes %>% select(id, node_id), by = c(\"to\" = \"id\")) %>%\n  rename(to_node = node_id)\n\n\n\n# Plot the Ego-Network\ng <- visNetwork(nodes = ego_nodes, edges = ego_edges, height = \"500px\", width = \"100%\") %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visNodes(color = group_colors) %>%\n  visEdges(arrows = 'to') %>%\n  visEdges(color = list(highlight = \"lightgray\")) %>%\n  visOptions(selectedBy = \"group\",\n             highlightNearest = list(enabled = TRUE,\n                                     degree = 1,\n                                     hover = TRUE,\n                                     labelOnly = TRUE),\n             nodesIdSelection = TRUE) %>%\n  visGroups(groupname = \"Unstable_Supplier\", color = \"yellow\") %>%    \n  visGroups(groupname = \"Stable_Supplier\", color = \"grey\") %>%\n  visGroups(groupname = \"Unstable_Buyer\", color = \"orange\") %>%  \n  visGroups(groupname = \"Stable_Buyer\", color = \"cadetblue\") %>%  \n  visGroups(groupname = \"Unstable_Wholesaler\", color = \"yellow\") %>% \n  visGroups(groupname = \"Stable_Wholesaler\", color = \"green\") %>% \n\n  visLegend() %>%\n  visInteraction(navigationButtons = TRUE) %>%\n  visLayout(randomSeed = 123)\ng\n\n\n\n\n\n\n\n\n\n\n\nshow the code\n# Aggregating and filtering edges data\nmc2_edges_aggregated <- mc2_edges %>%\n  filter(hscode == \"306170\"& Year == \"2029\") %>%\n  group_by(from = source, to = target, hscode, Year) %>%\n  summarise(weights = n()) %>%\n  filter(from != to) %>%\n  filter(weights > 20) %>%\n  ungroup()\n\n# Extracting unique node IDs\nid1 <- mc2_edges_aggregated %>%\n  select(from) %>%\n  rename(id = from)\nid2 <- mc2_edges_aggregated %>%\n  select(to) %>%\n  rename(id = to)\nmc2_nodes_extracted <- rbind(id1, id2) %>%\n  distinct()\n\n# Joining extracted nodes with company data to add running_year_category information\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  left_join(node_data_feature %>% distinct(ID, size_all, Company_group), by = c(\"id\" = \"ID\")) \n\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  rename(group = Company_group)\n\n\nego_edges <- mc2_edges_aggregated %>%\n  filter(from == \"hǎi dǎn Corporation Wharf\" | to == \"hǎi dǎn Corporation Wharf\")\n\n# Extract unique node IDs from ego_edges\nego_node_ids <- unique(c(ego_edges$from, ego_edges$to))\n\n# Filter ego_nodes using the unique node IDs\nego_nodes <- mc2_nodes_extracted %>%\n  filter(id %in% ego_node_ids) %>%\n  mutate(node_id = row_number())\n\n# Set the node size\nego_nodes <- ego_nodes %>%\n  rename(size = size_all) %>%\n  mutate(size = size * 100)\n\n\n# Update ego_edges with the corresponding node IDs\nego_edges <- ego_edges %>%\n  left_join(ego_nodes %>% select(id, node_id), by = c(\"from\" = \"id\")) %>%\n  rename(from_node = node_id) %>%\n  left_join(ego_nodes %>% select(id, node_id), by = c(\"to\" = \"id\")) %>%\n  rename(to_node = node_id)\n\n\n\n# Plot the Ego-Network\ng <- visNetwork(nodes = ego_nodes, edges = ego_edges, height = \"500px\", width = \"100%\") %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visNodes(color = group_colors) %>%\n  visEdges(arrows = 'to') %>%\n  visEdges(color = list(highlight = \"lightgray\")) %>%\n  visOptions(selectedBy = \"group\",\n             highlightNearest = list(enabled = TRUE,\n                                     degree = 1,\n                                     hover = TRUE,\n                                     labelOnly = TRUE),\n             nodesIdSelection = TRUE) %>%\n  visGroups(groupname = \"Unstable_Supplier\", color = \"yellow\") %>%    \n  visGroups(groupname = \"Stable_Supplier\", color = \"grey\") %>%\n  visGroups(groupname = \"Unstable_Buyer\", color = \"orange\") %>%  \n  visGroups(groupname = \"Stable_Buyer\", color = \"cadetblue\") %>%  \n  visGroups(groupname = \"Unstable_Wholesaler\", color = \"yellow\") %>% \n  visGroups(groupname = \"Stable_Wholesaler\", color = \"green\") %>% \n\n  visLegend() %>%\n  visInteraction(navigationButtons = TRUE) %>%\n  visLayout(randomSeed = 123)\ng\n\n\n\n\n\n\n\n\n\n\n\nshow the code\n# Aggregating and filtering edges data\nmc2_edges_aggregated <- mc2_edges %>%\n  filter(hscode == \"306170\"& Year == \"2030\") %>%\n  group_by(from = source, to = target, hscode, Year) %>%\n  summarise(weights = n()) %>%\n  filter(from != to) %>%\n  filter(weights > 20) %>%\n  ungroup()\n\n# Extracting unique node IDs\nid1 <- mc2_edges_aggregated %>%\n  select(from) %>%\n  rename(id = from)\nid2 <- mc2_edges_aggregated %>%\n  select(to) %>%\n  rename(id = to)\nmc2_nodes_extracted <- rbind(id1, id2) %>%\n  distinct()\n\n# Joining extracted nodes with company data to add running_year_category information\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  left_join(node_data_feature %>% distinct(ID, size_all, Company_group), by = c(\"id\" = \"ID\")) \n\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  rename(group = Company_group)\n\n\nego_edges <- mc2_edges_aggregated %>%\n  filter(from == \"hǎi dǎn Corporation Wharf\" | to == \"hǎi dǎn Corporation Wharf\")\n\n# Extract unique node IDs from ego_edges\nego_node_ids <- unique(c(ego_edges$from, ego_edges$to))\n\n# Filter ego_nodes using the unique node IDs\nego_nodes <- mc2_nodes_extracted %>%\n  filter(id %in% ego_node_ids) %>%\n  mutate(node_id = row_number())\n\n# Set the node size\nego_nodes <- ego_nodes %>%\n  rename(size = size_all) %>%\n  mutate(size = size * 100)\n\n\n# Update ego_edges with the corresponding node IDs\nego_edges <- ego_edges %>%\n  left_join(ego_nodes %>% select(id, node_id), by = c(\"from\" = \"id\")) %>%\n  rename(from_node = node_id) %>%\n  left_join(ego_nodes %>% select(id, node_id), by = c(\"to\" = \"id\")) %>%\n  rename(to_node = node_id)\n\n\n\n# Plot the Ego-Network\ng <- visNetwork(nodes = ego_nodes, edges = ego_edges, height = \"500px\", width = \"100%\") %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visNodes(color = group_colors) %>%\n  visEdges(arrows = 'to') %>%\n  visEdges(color = list(highlight = \"lightgray\")) %>%\n  visOptions(selectedBy = \"group\",\n             highlightNearest = list(enabled = TRUE,\n                                     degree = 1,\n                                     hover = TRUE,\n                                     labelOnly = TRUE),\n             nodesIdSelection = TRUE) %>%\n  visGroups(groupname = \"Unstable_Supplier\", color = \"yellow\") %>%    \n  visGroups(groupname = \"Stable_Supplier\", color = \"grey\") %>%\n  visGroups(groupname = \"Unstable_Buyer\", color = \"orange\") %>%  \n  visGroups(groupname = \"Stable_Buyer\", color = \"cadetblue\") %>%  \n  visGroups(groupname = \"Unstable_Wholesaler\", color = \"yellow\") %>% \n  visGroups(groupname = \"Stable_Wholesaler\", color = \"green\") %>% \n\n  visLegend() %>%\n  visInteraction(navigationButtons = TRUE) %>%\n  visLayout(randomSeed = 123)\ng\n\n\n\n\n\n\n\n\n\n\n\nshow the code\n# Aggregating and filtering edges data\nmc2_edges_aggregated <- mc2_edges %>%\n  filter(hscode == \"306170\"& Year == \"2031\") %>%\n  group_by(from = source, to = target, hscode, Year) %>%\n  summarise(weights = n()) %>%\n  filter(from != to) %>%\n  filter(weights > 20) %>%\n  ungroup()\n\n# Extracting unique node IDs\nid1 <- mc2_edges_aggregated %>%\n  select(from) %>%\n  rename(id = from)\nid2 <- mc2_edges_aggregated %>%\n  select(to) %>%\n  rename(id = to)\nmc2_nodes_extracted <- rbind(id1, id2) %>%\n  distinct()\n\n# Joining extracted nodes with company data to add running_year_category information\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  left_join(node_data_feature %>% distinct(ID, size_all, Company_group), by = c(\"id\" = \"ID\")) \n\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  rename(group = Company_group)\n\n\nego_edges <- mc2_edges_aggregated %>%\n  filter(from == \"hǎi dǎn Corporation Wharf\" | to == \"hǎi dǎn Corporation Wharf\")\n\n# Extract unique node IDs from ego_edges\nego_node_ids <- unique(c(ego_edges$from, ego_edges$to))\n\n# Filter ego_nodes using the unique node IDs\nego_nodes <- mc2_nodes_extracted %>%\n  filter(id %in% ego_node_ids) %>%\n  mutate(node_id = row_number())\n\n# Set the node size\nego_nodes <- ego_nodes %>%\n  rename(size = size_all) %>%\n  mutate(size = size * 100)\n\n\n# Update ego_edges with the corresponding node IDs\nego_edges <- ego_edges %>%\n  left_join(ego_nodes %>% select(id, node_id), by = c(\"from\" = \"id\")) %>%\n  rename(from_node = node_id) %>%\n  left_join(ego_nodes %>% select(id, node_id), by = c(\"to\" = \"id\")) %>%\n  rename(to_node = node_id)\n\n\n\n# Plot the Ego-Network\ng <- visNetwork(nodes = ego_nodes, edges = ego_edges, height = \"500px\", width = \"100%\") %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visNodes(color = group_colors) %>%\n  visEdges(arrows = 'to') %>%\n  visEdges(color = list(highlight = \"lightgray\")) %>%\n  visOptions(selectedBy = \"group\",\n             highlightNearest = list(enabled = TRUE,\n                                     degree = 1,\n                                     hover = TRUE,\n                                     labelOnly = TRUE),\n             nodesIdSelection = TRUE) %>%\n  visGroups(groupname = \"Unstable_Supplier\", color = \"yellow\") %>%    \n  visGroups(groupname = \"Stable_Supplier\", color = \"grey\") %>%\n  visGroups(groupname = \"Unstable_Buyer\", color = \"orange\") %>%  \n  visGroups(groupname = \"Stable_Buyer\", color = \"cadetblue\") %>%  \n  visGroups(groupname = \"Unstable_Wholesaler\", color = \"yellow\") %>% \n  visGroups(groupname = \"Stable_Wholesaler\", color = \"green\") %>% \n\n  visLegend() %>%\n  visInteraction(navigationButtons = TRUE) %>%\n  visLayout(randomSeed = 123)\ng\n\n\n\n\n\n\n\n\n\n\n\nshow the code\n# Aggregating and filtering edges data\nmc2_edges_aggregated <- mc2_edges %>%\n  filter(hscode == \"306170\"& Year == \"2032\") %>%\n  group_by(from = source, to = target, hscode, Year) %>%\n  summarise(weights = n()) %>%\n  filter(from != to) %>%\n  filter(weights > 20) %>%\n  ungroup()\n\n# Extracting unique node IDs\nid1 <- mc2_edges_aggregated %>%\n  select(from) %>%\n  rename(id = from)\nid2 <- mc2_edges_aggregated %>%\n  select(to) %>%\n  rename(id = to)\nmc2_nodes_extracted <- rbind(id1, id2) %>%\n  distinct()\n\n# Joining extracted nodes with company data to add running_year_category information\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  left_join(node_data_feature %>% distinct(ID, size_all, Company_group), by = c(\"id\" = \"ID\")) \n\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  rename(group = Company_group)\n\n\nego_edges <- mc2_edges_aggregated %>%\n  filter(from == \"hǎi dǎn Corporation Wharf\" | to == \"hǎi dǎn Corporation Wharf\")\n\n# Extract unique node IDs from ego_edges\nego_node_ids <- unique(c(ego_edges$from, ego_edges$to))\n\n# Filter ego_nodes using the unique node IDs\nego_nodes <- mc2_nodes_extracted %>%\n  filter(id %in% ego_node_ids) %>%\n  mutate(node_id = row_number())\n\n# Set the node size\nego_nodes <- ego_nodes %>%\n  rename(size = size_all) %>%\n  mutate(size = size * 100)\n\n\n# Update ego_edges with the corresponding node IDs\nego_edges <- ego_edges %>%\n  left_join(ego_nodes %>% select(id, node_id), by = c(\"from\" = \"id\")) %>%\n  rename(from_node = node_id) %>%\n  left_join(ego_nodes %>% select(id, node_id), by = c(\"to\" = \"id\")) %>%\n  rename(to_node = node_id)\n\n\n\n# Plot the Ego-Network\ng <- visNetwork(nodes = ego_nodes, edges = ego_edges, height = \"500px\", width = \"100%\") %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visNodes(color = group_colors) %>%\n  visEdges(arrows = 'to') %>%\n  visEdges(color = list(highlight = \"lightgray\")) %>%\n  visOptions(selectedBy = \"group\",\n             highlightNearest = list(enabled = TRUE,\n                                     degree = 1,\n                                     hover = TRUE,\n                                     labelOnly = TRUE),\n             nodesIdSelection = TRUE) %>%\n  visGroups(groupname = \"Unstable_Supplier\", color = \"yellow\") %>%    \n  visGroups(groupname = \"Stable_Supplier\", color = \"grey\") %>%\n  visGroups(groupname = \"Unstable_Buyer\", color = \"orange\") %>%  \n  visGroups(groupname = \"Stable_Buyer\", color = \"cadetblue\") %>%  \n  visGroups(groupname = \"Unstable_Wholesaler\", color = \"yellow\") %>% \n  visGroups(groupname = \"Stable_Wholesaler\", color = \"green\") %>% \n\n  visLegend() %>%\n  visInteraction(navigationButtons = TRUE) %>%\n  visLayout(randomSeed = 123)\ng\n\n\n\n\n\n\n\n\n\n\n\nshow the code\n# Aggregating and filtering edges data\nmc2_edges_aggregated <- mc2_edges %>%\n  filter(hscode == \"306170\"& Year == \"2033\") %>%\n  group_by(from = source, to = target, hscode, Year) %>%\n  summarise(weights = n()) %>%\n  filter(from != to) %>%\n  filter(weights > 20) %>%\n  ungroup()\n\n# Extracting unique node IDs\nid1 <- mc2_edges_aggregated %>%\n  select(from) %>%\n  rename(id = from)\nid2 <- mc2_edges_aggregated %>%\n  select(to) %>%\n  rename(id = to)\nmc2_nodes_extracted <- rbind(id1, id2) %>%\n  distinct()\n\n# Joining extracted nodes with company data to add running_year_category information\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  left_join(node_data_feature %>% distinct(ID, size_all, Company_group), by = c(\"id\" = \"ID\")) \n\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  rename(group = Company_group)\n\n\nego_edges <- mc2_edges_aggregated %>%\n  filter(from == \"hǎi dǎn Corporation Wharf\" | to == \"hǎi dǎn Corporation Wharf\")\n\n# Extract unique node IDs from ego_edges\nego_node_ids <- unique(c(ego_edges$from, ego_edges$to))\n\n# Filter ego_nodes using the unique node IDs\nego_nodes <- mc2_nodes_extracted %>%\n  filter(id %in% ego_node_ids) %>%\n  mutate(node_id = row_number())\n\n# Set the node size\nego_nodes <- ego_nodes %>%\n  rename(size = size_all) %>%\n  mutate(size = size * 100)\n\n\n# Update ego_edges with the corresponding node IDs\nego_edges <- ego_edges %>%\n  left_join(ego_nodes %>% select(id, node_id), by = c(\"from\" = \"id\")) %>%\n  rename(from_node = node_id) %>%\n  left_join(ego_nodes %>% select(id, node_id), by = c(\"to\" = \"id\")) %>%\n  rename(to_node = node_id)\n\n\n\n# Plot the Ego-Network\ng <- visNetwork(nodes = ego_nodes, edges = ego_edges, height = \"500px\", width = \"100%\") %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visNodes(color = group_colors) %>%\n  visEdges(arrows = 'to') %>%\n  visEdges(color = list(highlight = \"lightgray\")) %>%\n  visOptions(selectedBy = \"group\",\n             highlightNearest = list(enabled = TRUE,\n                                     degree = 1,\n                                     hover = TRUE,\n                                     labelOnly = TRUE),\n             nodesIdSelection = TRUE) %>%\n  visGroups(groupname = \"Unstable_Supplier\", color = \"yellow\") %>%    \n  visGroups(groupname = \"Stable_Supplier\", color = \"grey\") %>%\n  visGroups(groupname = \"Unstable_Buyer\", color = \"orange\") %>%  \n  visGroups(groupname = \"Stable_Buyer\", color = \"cadetblue\") %>%  \n  visGroups(groupname = \"Unstable_Wholesaler\", color = \"yellow\") %>% \n  visGroups(groupname = \"Stable_Wholesaler\", color = \"green\") %>% \n\n  visLegend() %>%\n  visInteraction(navigationButtons = TRUE) %>%\n  visLayout(randomSeed = 123)\ng\n\n\n\n\n\n\n\n\n\n\n\nshow the code\n# Aggregating and filtering edges data\nmc2_edges_aggregated <- mc2_edges %>%\n  filter(hscode == \"306170\"& Year == \"2034\") %>%\n  group_by(from = source, to = target, hscode, Year) %>%\n  summarise(weights = n()) %>%\n  filter(from != to) %>%\n  filter(weights > 20) %>%\n  ungroup()\n\n# Extracting unique node IDs\nid1 <- mc2_edges_aggregated %>%\n  select(from) %>%\n  rename(id = from)\nid2 <- mc2_edges_aggregated %>%\n  select(to) %>%\n  rename(id = to)\nmc2_nodes_extracted <- rbind(id1, id2) %>%\n  distinct()\n\n# Joining extracted nodes with company data to add running_year_category information\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  left_join(node_data_feature %>% distinct(ID, size_all, Company_group), by = c(\"id\" = \"ID\")) \n\nmc2_nodes_extracted <- mc2_nodes_extracted %>%\n  rename(group = Company_group)\n\n\nego_edges <- mc2_edges_aggregated %>%\n  filter(from == \"hǎi dǎn Corporation Wharf\" | to == \"hǎi dǎn Corporation Wharf\")\n\n# Extract unique node IDs from ego_edges\nego_node_ids <- unique(c(ego_edges$from, ego_edges$to))\n\n# Filter ego_nodes using the unique node IDs\nego_nodes <- mc2_nodes_extracted %>%\n  filter(id %in% ego_node_ids) %>%\n  mutate(node_id = row_number())\n\n# Set the node size\nego_nodes <- ego_nodes %>%\n  rename(size = size_all) %>%\n  mutate(size = size * 100)\n\n\n# Update ego_edges with the corresponding node IDs\nego_edges <- ego_edges %>%\n  left_join(ego_nodes %>% select(id, node_id), by = c(\"from\" = \"id\")) %>%\n  rename(from_node = node_id) %>%\n  left_join(ego_nodes %>% select(id, node_id), by = c(\"to\" = \"id\")) %>%\n  rename(to_node = node_id)\n\n\n\n# Plot the Ego-Network\ng <- visNetwork(nodes = ego_nodes, edges = ego_edges, height = \"500px\", width = \"100%\") %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visNodes(color = group_colors) %>%\n  visEdges(arrows = 'to') %>%\n  visEdges(color = list(highlight = \"lightgray\")) %>%\n  visOptions(selectedBy = \"group\",\n             highlightNearest = list(enabled = TRUE,\n                                     degree = 1,\n                                     hover = TRUE,\n                                     labelOnly = TRUE),\n             nodesIdSelection = TRUE) %>%\n  visGroups(groupname = \"Unstable_Supplier\", color = \"yellow\") %>%    \n  visGroups(groupname = \"Stable_Supplier\", color = \"grey\") %>%\n  visGroups(groupname = \"Unstable_Buyer\", color = \"orange\") %>%  \n  visGroups(groupname = \"Stable_Buyer\", color = \"cadetblue\") %>%  \n  visGroups(groupname = \"Unstable_Wholesaler\", color = \"yellow\") %>% \n  visGroups(groupname = \"Stable_Wholesaler\", color = \"green\") %>% \n\n  visLegend() %>%\n  visInteraction(navigationButtons = TRUE) %>%\n  visLayout(randomSeed = 123)\ng\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nFiltering the mc2_edges_aggregated dataframe to extract the edges that involve the node “hǎi dǎn Corporation Wharf” as either the source or the target. The resulting subset is assigned to the ego_edges dataframe.\nExtracting the unique node IDs from the ego_edges dataframe.\nFiltering the mc2_nodes_extracted dataframe to select only the nodes whose IDs are present in the ego_node_ids vector. This is done using the %in% operator to match the values of the “id” column with the values in ego_node_ids."
  },
  {
    "objectID": "Take-home Exercise/Take-home Exercise 3/Take-home_Ex03.html",
    "href": "Take-home Exercise/Take-home Exercise 3/Take-home_Ex03.html",
    "title": "Take-home_Ex03",
    "section": "",
    "text": "FishEye International, a non-profit focused on countering illegal, unreported, and unregulated (IUU) fishing, has been given access to an international finance corporation’s database on fishing related companies. In the past, FishEye has determined that companies with anomalous structures are far more likely to be involved in IUU (or other “fishy” business). FishEye has transformed the database into a knowledge graph. It includes information about companies, owners, workers, and financial status. FishEye is aiming to use this graph to identify anomalies that could indicate a company is involved in IUU.\nFishEye analysts have attempted to use traditional node-link visualizations and standard graph analyses, but these were found to be ineffective because the scale and detail in the data can obscure a business’s true structure.\nThis exercise source is from: Mini-Challenge 3 task 2"
  },
  {
    "objectID": "Take-home Exercise/Take-home Exercise 3/Take-home_Ex03.html#install-r-packages-and-import-dataset",
    "href": "Take-home Exercise/Take-home Exercise 3/Take-home_Ex03.html#install-r-packages-and-import-dataset",
    "title": "Take-home_Ex03",
    "section": "2.1 Install R Packages and Import Dataset",
    "text": "2.1 Install R Packages and Import Dataset\nThe code chunk below uses pacman::p_load() to check if packages are installed. If they are, they will be launched into R. The packages installed are:\n\n\nshow the code\npacman::p_load(jsonlite, tidygraph, ggraph, visNetwork, lubridate, tidyverse,readxl,igraph)\n\n\njsonlite: A simple and robust JSON parser and generator for R.\ntidygraph: this package provides a tidy API for graph/network manipulation.\nggraph: ggiraph is a tool that allows you to create dynamic ggplot graphs.\nvisNetwork: an R package for network visualization, using vis.js javascript library.\nlubridate: an R package that makes it easier to work with dates and times.\ntidyverse: A collection of core packages designed for data science, used extensively for data preparation and wrangling.\nreadxl：An R package makes it easy to get data out of Excel and into R.\nigraph:igraph is a fast and open source library for the analysis of graphs or networks."
  },
  {
    "objectID": "Take-home Exercise/Take-home Exercise 3/Take-home_Ex03.html#data-introduction",
    "href": "Take-home Exercise/Take-home Exercise 3/Take-home_Ex03.html#data-introduction",
    "title": "Take-home_Ex03",
    "section": "2.2 Data Introduction",
    "text": "2.2 Data Introduction\nIn the code chunk below, fromJSON() of jsonlite package is used to import mc2_challenge_graph.json into R environment.\n\n\nshow the code\nMC3_data <- fromJSON(\"data/MC3.json\")\n\n\nFor the purpose of this study, a directed multi-graph is provided. There are totally 34552 nodes and 5464092 directed edges.\n\n\nshow the code\nMC3_nodes <- as_tibble(MC3_data$nodes) %>%\n  select(country,id,product_services,revenue_omu,type)\n\n\n\n\nshow the code\nMC3_edges <- as_tibble(MC3_data$links) %>%\n  select(source,target,type) %>% \n  distinct()"
  }
]